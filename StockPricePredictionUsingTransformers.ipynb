{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fovi-com/MLTradingBot/blob/main/StockPricePredictionUsingTransformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The source of this notebook is (https://colab.research.google.com/drive/1j3AYSIxhiNJSCP692pKPbLk4_-kG4Pmh?usp=sharing) which accompanies this Medium article:  **Stock Price Prediction Using Transformers\n",
        "Introduction: Evolving Landscape of Stock Price Prediction** (https://medium.com/@Matthew_Frank/stock-price-prediction-using-transformers-2d84341ff213).\n",
        "\n",
        "Modifications by Jim White (https://www.linkedin.com/in/jamespaulwhite/)."
      ],
      "metadata": {
        "id": "XXZF8Z7ip54S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l9XA0tN3DEr",
        "outputId": "e5fc6e0c-2c0d-48bd-9d30-d87d493c6dd5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ziguS6k842Uo"
      },
      "outputs": [],
      "source": [
        "def calculate_bollinger_bands(data, window=10, num_of_std=2):\n",
        "    \"\"\"Calculate Bollinger Bands\"\"\"\n",
        "    rolling_mean = data.rolling(window=window).mean()\n",
        "    rolling_std = data.rolling(window=window).std()\n",
        "    upper_band = rolling_mean + (rolling_std * num_of_std)\n",
        "    lower_band = rolling_mean - (rolling_std * num_of_std)\n",
        "    return upper_band, lower_band\n",
        "\n",
        "def calculate_rsi(data, window=10):\n",
        "    \"\"\"Calculate Relative Strength Index\"\"\"\n",
        "    delta = data.diff()\n",
        "    gain = delta.clip(lower=0)\n",
        "    loss = -delta.clip(upper=0)\n",
        "    avg_gain = gain.rolling(window=window, min_periods=1).mean()\n",
        "    avg_loss = loss.rolling(window=window, min_periods=1).mean()\n",
        "    rs = avg_gain / avg_loss\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "    return rsi\n",
        "\n",
        "def calculate_roc(data, periods=10):\n",
        "    \"\"\"Calculate Rate of Change.\"\"\"\n",
        "    roc = ((data - data.shift(periods)) / data.shift(periods)) * 100\n",
        "    return roc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AJOLtEZ04sYU"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, MultiHeadAttention, Add, GlobalAveragePooling1D\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RS9sQ0rD6RkC"
      },
      "outputs": [],
      "source": [
        "tickers = ['META', 'AAPL', 'MSFT', 'AMZN', 'GOOG']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YMAMF3D62zKD"
      },
      "outputs": [],
      "source": [
        "%load_ext dotenv\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.environ.get('POLYGON_API_KEY'):\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        try:\n",
        "            from google.colab import errors\n",
        "            os.environ['POLYGON_API_KEY'] = userdata.get('POLYGON_API_KEY').strip()\n",
        "        except Exception as ex:\n",
        "            print(ex)\n",
        "            pass\n",
        "        except errors.Error as err:\n",
        "            print(err)\n",
        "            pass\n",
        "    except ModuleNotFoundError:\n",
        "        pass\n",
        "\n",
        "    if not os.environ.get('POLYGON_API_KEY'):\n",
        "        import getpass\n",
        "        os.environ['POLYGON_API_KEY'] = getpass.getpass('Enter your Polygon API key: ').strip()\n",
        "\n",
        "    if not os.environ.get('POLYGON_API_KEY'):\n",
        "        raise ValueError('No Polygon API key provided')\n",
        "\n",
        "\n",
        "API_KEY = os.getenv('POLYGON_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "p4zRcn2p2zKD"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Function to get data from Polygon.io\n",
        "def get_polygon_data(ticker, api_key, multiplier='1', timespan='minute', from_date='2022-01-01', to_date='2022-12-31'):\n",
        "    url = f'https://api.polygon.io/v2/aggs/ticker/{ticker}/range/{multiplier}/{timespan}/{from_date}/{to_date}'\n",
        "    params = {\n",
        "        'adjusted': 'true',\n",
        "        'sort': 'asc',\n",
        "        'apiKey': api_key\n",
        "    }\n",
        "    response = requests.get(url, params=params)\n",
        "    data = response.json()\n",
        "    df = pd.DataFrame(data['results'])\n",
        "    df['timestamp'] = pd.to_datetime(df['t'], unit='ms')\n",
        "    df.set_index('timestamp', inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "ticker_data_frames = []\n",
        "stats = {}\n",
        "\n",
        "\n",
        "from_date=\"2023-03-01\"\n",
        "to_date=\"2023-05-01\"\n",
        "data_folder = \"data\"\n",
        "\n",
        "for ticker in tickers:\n",
        "    saved_file_name = f'./{ticker}_{from_date}_{to_date}.csv'\n",
        "    saved_file_path = os.path.join(data_folder, saved_file_name)\n",
        "    # Download historical data for the ticker\n",
        "    if os.path.exists(saved_file_path):\n",
        "        data = pd.read_csv(saved_file_path)\n",
        "    else:\n",
        "        data = get_polygon_data(ticker, API_KEY, from_date=from_date, to_date=to_date)\n",
        "        #create a folder if it does not exist\n",
        "        if not os.path.exists(data_folder):\n",
        "            os.makedirs(data_folder)\n",
        "        data.to_csv(saved_file_path)\n",
        "\n",
        "\n",
        "    # Calculate the daily percentage change\n",
        "    close = data['c']\n",
        "    upper, lower = calculate_bollinger_bands(close, window=14, num_of_std=2)\n",
        "    width = upper - lower\n",
        "    rsi = calculate_rsi(close, window=14)\n",
        "    roc = calculate_roc(close, periods=14)\n",
        "    volume = data['v']\n",
        "    diff = close.diff(1)\n",
        "    percent_change_close = close.pct_change() * 100\n",
        "\n",
        "    # Create a DataFrame for the current ticker and append it to the list\n",
        "    ticker_df = pd.DataFrame({\n",
        "        ticker+'_close': close,\n",
        "        ticker+'_width': width,\n",
        "        ticker+'_rsi': rsi,\n",
        "        ticker+'_roc': roc,\n",
        "        ticker+'_volume': volume,\n",
        "        ticker+'_diff': diff,\n",
        "        ticker+'_percent_change_close': percent_change_close,\n",
        "    })\n",
        "\n",
        "    MEAN = ticker_df.mean()\n",
        "    STD = ticker_df.std()\n",
        "\n",
        "    # Keep track of mean and std\n",
        "    for column in MEAN.index:\n",
        "        stats[f\"{column}_mean\"] = MEAN[column]\n",
        "        stats[f\"{column}_std\"] = STD[column]\n",
        "\n",
        "    # Normalize the training features\n",
        "    ticker_df = (ticker_df - MEAN) / STD\n",
        "\n",
        "    ticker_data_frames.append(ticker_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f\"{len(ticker_data_frames)=}\""
      ],
      "metadata": {
        "id": "A5g75QMe4wzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ticker_data_frames[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "_ops0gFp6LoG",
        "outputId": "c0db8232-2829-471b-94fe-f88c78f46d90"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     AMZN_close  AMZN_width  AMZN_rsi  AMZN_roc  AMZN_volume  \\\n",
              "timestamp                                                                      \n",
              "2023-03-01 09:00:00    0.889262         NaN       NaN       NaN    -0.653276   \n",
              "2023-03-01 09:01:00    1.049595         NaN  3.160380       NaN    -0.664037   \n",
              "2023-03-01 09:02:00    0.965611         NaN  1.008604       NaN    -0.673217   \n",
              "2023-03-01 09:03:00    0.950341         NaN  0.766961       NaN    -0.671779   \n",
              "2023-03-01 09:04:00    1.080135         NaN  1.564767       NaN    -0.658064   \n",
              "...                         ...         ...       ...       ...          ...   \n",
              "2023-03-09 17:54:00    0.977063    0.830705 -1.038007 -1.119351     0.668118   \n",
              "2023-03-09 17:55:00    0.946524    0.553118 -1.749664 -1.706029     0.123838   \n",
              "2023-03-09 17:56:00    1.003786    0.214091 -1.173823 -1.177988     0.231965   \n",
              "2023-03-09 17:57:00    0.969428   -0.091438 -1.161148 -1.158595    -0.250340   \n",
              "2023-03-09 17:58:00    1.034325   -0.295717 -0.491253 -0.511508     0.368850   \n",
              "\n",
              "                     AMZN_diff  AMZN_percent_change_close  \n",
              "timestamp                                                  \n",
              "2023-03-01 09:00:00        NaN                        NaN  \n",
              "2023-03-01 09:01:00   2.972117                   2.937619  \n",
              "2023-03-01 09:02:00  -1.557643                  -1.536730  \n",
              "2023-03-01 09:03:00  -0.283648                  -0.280473  \n",
              "2023-03-01 09:04:00   2.405897                   2.375890  \n",
              "...                        ...                        ...  \n",
              "2023-03-09 17:54:00  -0.779091                  -0.769143  \n",
              "2023-03-09 17:55:00  -0.566758                  -0.559949  \n",
              "2023-03-09 17:56:00   1.061125                   1.047735  \n",
              "2023-03-09 17:57:00  -0.637536                  -0.629597  \n",
              "2023-03-09 17:58:00   1.202680                   1.187177  \n",
              "\n",
              "[5000 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c44e26af-423c-4662-ac9c-e7735d9a26cc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AMZN_close</th>\n",
              "      <th>AMZN_width</th>\n",
              "      <th>AMZN_rsi</th>\n",
              "      <th>AMZN_roc</th>\n",
              "      <th>AMZN_volume</th>\n",
              "      <th>AMZN_diff</th>\n",
              "      <th>AMZN_percent_change_close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-03-01 09:00:00</th>\n",
              "      <td>0.889262</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.653276</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-01 09:01:00</th>\n",
              "      <td>1.049595</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.160380</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.664037</td>\n",
              "      <td>2.972117</td>\n",
              "      <td>2.937619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-01 09:02:00</th>\n",
              "      <td>0.965611</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.008604</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.673217</td>\n",
              "      <td>-1.557643</td>\n",
              "      <td>-1.536730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-01 09:03:00</th>\n",
              "      <td>0.950341</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.766961</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.671779</td>\n",
              "      <td>-0.283648</td>\n",
              "      <td>-0.280473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-01 09:04:00</th>\n",
              "      <td>1.080135</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.564767</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.658064</td>\n",
              "      <td>2.405897</td>\n",
              "      <td>2.375890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-09 17:54:00</th>\n",
              "      <td>0.977063</td>\n",
              "      <td>0.830705</td>\n",
              "      <td>-1.038007</td>\n",
              "      <td>-1.119351</td>\n",
              "      <td>0.668118</td>\n",
              "      <td>-0.779091</td>\n",
              "      <td>-0.769143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-09 17:55:00</th>\n",
              "      <td>0.946524</td>\n",
              "      <td>0.553118</td>\n",
              "      <td>-1.749664</td>\n",
              "      <td>-1.706029</td>\n",
              "      <td>0.123838</td>\n",
              "      <td>-0.566758</td>\n",
              "      <td>-0.559949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-09 17:56:00</th>\n",
              "      <td>1.003786</td>\n",
              "      <td>0.214091</td>\n",
              "      <td>-1.173823</td>\n",
              "      <td>-1.177988</td>\n",
              "      <td>0.231965</td>\n",
              "      <td>1.061125</td>\n",
              "      <td>1.047735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-09 17:57:00</th>\n",
              "      <td>0.969428</td>\n",
              "      <td>-0.091438</td>\n",
              "      <td>-1.161148</td>\n",
              "      <td>-1.158595</td>\n",
              "      <td>-0.250340</td>\n",
              "      <td>-0.637536</td>\n",
              "      <td>-0.629597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-09 17:58:00</th>\n",
              "      <td>1.034325</td>\n",
              "      <td>-0.295717</td>\n",
              "      <td>-0.491253</td>\n",
              "      <td>-0.511508</td>\n",
              "      <td>0.368850</td>\n",
              "      <td>1.202680</td>\n",
              "      <td>1.187177</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c44e26af-423c-4662-ac9c-e7735d9a26cc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c44e26af-423c-4662-ac9c-e7735d9a26cc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c44e26af-423c-4662-ac9c-e7735d9a26cc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a17519d4-e1da-4ab3-b8bd-abbb430450f6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a17519d4-e1da-4ab3-b8bd-abbb430450f6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a17519d4-e1da-4ab3-b8bd-abbb430450f6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"ticker_data_frames[3]\",\n  \"rows\": 5000,\n  \"fields\": [\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2023-03-01 09:00:00\",\n        \"max\": \"2023-03-09 17:58:00\",\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          \"2023-03-02 23:15:00\",\n          \"2023-03-06 14:47:00\",\n          \"2023-03-06 15:54:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AMZN_close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -2.324970229455644,\n        \"max\": 2.3169946833915014,\n        \"num_unique_values\": 1747,\n        \"samples\": [\n          1.274825880280211,\n          0.7327454039366013,\n          -1.5195608005896304\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AMZN_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9999999999999999,\n        \"min\": -1.227138383818406,\n        \"max\": 6.987135680510842,\n        \"num_unique_values\": 4864,\n        \"samples\": [\n          -1.0776654935616945,\n          0.9589356415068269,\n          -0.22676216534266777\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AMZN_rsi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -2.8843093695200195,\n        \"max\": 3.160380297388035,\n        \"num_unique_values\": 4486,\n        \"samples\": [\n          -0.4586691638062924,\n          0.10691498641997291,\n          -1.086883033660452\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AMZN_roc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9999999999999999,\n        \"min\": -6.6649134243983355,\n        \"max\": 5.259062518714536,\n        \"num_unique_values\": 4477,\n        \"samples\": [\n          -0.1998792178506255,\n          1.0565432320418617,\n          -0.32212745833543255\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AMZN_volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9999999999999999,\n        \"min\": -0.6845602364902718,\n        \"max\": 17.864344141398202,\n        \"num_unique_values\": 4338,\n        \"samples\": [\n          -0.6552747466660154,\n          -0.6746446769434763,\n          0.6250183489692188\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AMZN_diff\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9999999999999999,\n        \"min\": -8.975126546322137,\n        \"max\": 9.117021087299891,\n        \"num_unique_values\": 1249,\n        \"samples\": [\n          -0.7649351469787463,\n          -4.199060032290261,\n          -0.20579280167857975\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AMZN_percent_change_close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -8.919577521134485,\n        \"max\": 9.12126801304961,\n        \"num_unique_values\": 4038,\n        \"samples\": [\n          1.2765457541885468,\n          -0.14021936723577105,\n          0.2777147142403017\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "PoLOIDNN6jFB",
        "outputId": "fe84fdef-4984-4d8e-e9ae-a2f55053f813"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   META_close_mean  META_close_std  META_width_mean  META_width_std  \\\n",
              "0       181.888926        5.064389         0.884587         0.62428   \n",
              "\n",
              "   META_rsi_mean  META_rsi_std  META_roc_mean  META_roc_std  META_volume_mean  \\\n",
              "0      50.364641     17.046862       0.010671      0.353776         40953.215   \n",
              "\n",
              "   META_volume_std  ...  GOOG_rsi_mean  GOOG_rsi_std  GOOG_roc_mean  \\\n",
              "0     58312.124902  ...      49.670408     16.118251       0.002755   \n",
              "\n",
              "   GOOG_roc_std  GOOG_volume_mean  GOOG_volume_std  GOOG_diff_mean  \\\n",
              "0      0.277204        38381.1966     51424.301577        0.000192   \n",
              "\n",
              "   GOOG_diff_std  GOOG_percent_change_close_mean  \\\n",
              "0       0.076649                        0.000245   \n",
              "\n",
              "   GOOG_percent_change_close_std  \n",
              "0                       0.082652  \n",
              "\n",
              "[1 rows x 70 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d1a74ab-5489-4592-9a65-5dbb4043cfd3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>META_close_mean</th>\n",
              "      <th>META_close_std</th>\n",
              "      <th>META_width_mean</th>\n",
              "      <th>META_width_std</th>\n",
              "      <th>META_rsi_mean</th>\n",
              "      <th>META_rsi_std</th>\n",
              "      <th>META_roc_mean</th>\n",
              "      <th>META_roc_std</th>\n",
              "      <th>META_volume_mean</th>\n",
              "      <th>META_volume_std</th>\n",
              "      <th>...</th>\n",
              "      <th>GOOG_rsi_mean</th>\n",
              "      <th>GOOG_rsi_std</th>\n",
              "      <th>GOOG_roc_mean</th>\n",
              "      <th>GOOG_roc_std</th>\n",
              "      <th>GOOG_volume_mean</th>\n",
              "      <th>GOOG_volume_std</th>\n",
              "      <th>GOOG_diff_mean</th>\n",
              "      <th>GOOG_diff_std</th>\n",
              "      <th>GOOG_percent_change_close_mean</th>\n",
              "      <th>GOOG_percent_change_close_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>181.888926</td>\n",
              "      <td>5.064389</td>\n",
              "      <td>0.884587</td>\n",
              "      <td>0.62428</td>\n",
              "      <td>50.364641</td>\n",
              "      <td>17.046862</td>\n",
              "      <td>0.010671</td>\n",
              "      <td>0.353776</td>\n",
              "      <td>40953.215</td>\n",
              "      <td>58312.124902</td>\n",
              "      <td>...</td>\n",
              "      <td>49.670408</td>\n",
              "      <td>16.118251</td>\n",
              "      <td>0.002755</td>\n",
              "      <td>0.277204</td>\n",
              "      <td>38381.1966</td>\n",
              "      <td>51424.301577</td>\n",
              "      <td>0.000192</td>\n",
              "      <td>0.076649</td>\n",
              "      <td>0.000245</td>\n",
              "      <td>0.082652</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 70 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d1a74ab-5489-4592-9a65-5dbb4043cfd3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6d1a74ab-5489-4592-9a65-5dbb4043cfd3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6d1a74ab-5489-4592-9a65-5dbb4043cfd3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "stats"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Convert stats from dict to df\n",
        "stats = pd.DataFrame([stats], index=[0])\n",
        "stats.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "qekxvEZk7woI",
        "outputId": "63ab08e4-33d9-4250-cabc-9fcd77f5548f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     META_close  META_width  META_rsi  META_roc  META_volume  \\\n",
              "timestamp                                                                      \n",
              "2023-03-01 10:55:00   -1.190455   -0.478390 -0.092067 -0.094443    -0.682452   \n",
              "2023-03-01 12:00:00   -1.261539   -0.657236 -0.830519 -0.801155    -0.609431   \n",
              "2023-03-01 12:01:00   -1.281285   -0.663242 -0.600536 -0.528861    -0.675918   \n",
              "2023-03-01 12:09:00   -1.285234   -0.438536 -0.233421 -0.223439    -0.674958   \n",
              "2023-03-01 13:00:00   -1.330649   -1.042758 -0.836138 -0.352565    -0.110838   \n",
              "\n",
              "                     META_diff  META_percent_change_close  AAPL_close  \\\n",
              "timestamp                                                               \n",
              "2023-03-01 10:55:00   0.873902                   0.903757   -0.539978   \n",
              "2023-03-01 12:00:00  -0.612235                  -0.634117   -0.579376   \n",
              "2023-03-01 12:01:00  -0.557193                  -0.577498   -0.576562   \n",
              "2023-03-01 12:09:00   0.158355                   0.163795   -0.573748   \n",
              "2023-03-01 13:00:00  -0.832403                  -0.863530   -0.607518   \n",
              "\n",
              "                     AAPL_width  AAPL_rsi  ...  AMZN_volume  AMZN_diff  \\\n",
              "timestamp                                  ...                           \n",
              "2023-03-01 10:55:00   -0.798726  1.183924  ...    -0.674820   0.282572   \n",
              "2023-03-01 12:00:00   -0.340900 -1.306480  ...    -0.619763  -1.840753   \n",
              "2023-03-01 12:01:00   -0.351032 -1.212886  ...    -0.637717  -0.566758   \n",
              "2023-03-01 12:09:00   -0.943849 -0.826813  ...    -0.656439  -0.708313   \n",
              "2023-03-01 13:00:00   -0.953176 -0.367317  ...    -0.263616  -0.991423   \n",
              "\n",
              "                     AMZN_percent_change_close  GOOG_close  GOOG_width  \\\n",
              "timestamp                                                                \n",
              "2023-03-01 10:55:00                   0.278420   -1.211776   -0.548373   \n",
              "2023-03-01 12:00:00                  -1.816162   -1.211776   -0.498211   \n",
              "2023-03-01 12:01:00                  -0.560215   -1.243933   -0.498211   \n",
              "2023-03-01 12:09:00                  -0.700189   -1.227854   -0.386283   \n",
              "2023-03-01 13:00:00                  -0.981247   -1.302887   -0.299948   \n",
              "\n",
              "                     GOOG_rsi  GOOG_roc  GOOG_volume  GOOG_diff  \\\n",
              "timestamp                                                         \n",
              "2023-03-01 10:55:00  0.703956  0.506604    -0.740160   0.780287   \n",
              "2023-03-01 12:00:00 -0.065720 -0.089276    -0.609579  -1.046229   \n",
              "2023-03-01 12:01:00  0.020448 -0.009939    -0.725731  -0.785298   \n",
              "2023-03-01 12:09:00 -0.379819 -0.327183    -0.726256   0.127960   \n",
              "2023-03-01 13:00:00 -1.819765 -1.395900    -0.301729  -0.263436   \n",
              "\n",
              "                     GOOG_percent_change_close  \n",
              "timestamp                                       \n",
              "2023-03-01 10:55:00                   0.795998  \n",
              "2023-03-01 12:00:00                  -1.066610  \n",
              "2023-03-01 12:01:00                  -0.801400  \n",
              "2023-03-01 12:09:00                   0.130166  \n",
              "2023-03-01 13:00:00                  -0.269550  \n",
              "\n",
              "[5 rows x 35 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1889e7fd-a798-4da0-b14c-314afa317d20\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>META_close</th>\n",
              "      <th>META_width</th>\n",
              "      <th>META_rsi</th>\n",
              "      <th>META_roc</th>\n",
              "      <th>META_volume</th>\n",
              "      <th>META_diff</th>\n",
              "      <th>META_percent_change_close</th>\n",
              "      <th>AAPL_close</th>\n",
              "      <th>AAPL_width</th>\n",
              "      <th>AAPL_rsi</th>\n",
              "      <th>...</th>\n",
              "      <th>AMZN_volume</th>\n",
              "      <th>AMZN_diff</th>\n",
              "      <th>AMZN_percent_change_close</th>\n",
              "      <th>GOOG_close</th>\n",
              "      <th>GOOG_width</th>\n",
              "      <th>GOOG_rsi</th>\n",
              "      <th>GOOG_roc</th>\n",
              "      <th>GOOG_volume</th>\n",
              "      <th>GOOG_diff</th>\n",
              "      <th>GOOG_percent_change_close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-03-01 10:55:00</th>\n",
              "      <td>-1.190455</td>\n",
              "      <td>-0.478390</td>\n",
              "      <td>-0.092067</td>\n",
              "      <td>-0.094443</td>\n",
              "      <td>-0.682452</td>\n",
              "      <td>0.873902</td>\n",
              "      <td>0.903757</td>\n",
              "      <td>-0.539978</td>\n",
              "      <td>-0.798726</td>\n",
              "      <td>1.183924</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.674820</td>\n",
              "      <td>0.282572</td>\n",
              "      <td>0.278420</td>\n",
              "      <td>-1.211776</td>\n",
              "      <td>-0.548373</td>\n",
              "      <td>0.703956</td>\n",
              "      <td>0.506604</td>\n",
              "      <td>-0.740160</td>\n",
              "      <td>0.780287</td>\n",
              "      <td>0.795998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-01 12:00:00</th>\n",
              "      <td>-1.261539</td>\n",
              "      <td>-0.657236</td>\n",
              "      <td>-0.830519</td>\n",
              "      <td>-0.801155</td>\n",
              "      <td>-0.609431</td>\n",
              "      <td>-0.612235</td>\n",
              "      <td>-0.634117</td>\n",
              "      <td>-0.579376</td>\n",
              "      <td>-0.340900</td>\n",
              "      <td>-1.306480</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.619763</td>\n",
              "      <td>-1.840753</td>\n",
              "      <td>-1.816162</td>\n",
              "      <td>-1.211776</td>\n",
              "      <td>-0.498211</td>\n",
              "      <td>-0.065720</td>\n",
              "      <td>-0.089276</td>\n",
              "      <td>-0.609579</td>\n",
              "      <td>-1.046229</td>\n",
              "      <td>-1.066610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-01 12:01:00</th>\n",
              "      <td>-1.281285</td>\n",
              "      <td>-0.663242</td>\n",
              "      <td>-0.600536</td>\n",
              "      <td>-0.528861</td>\n",
              "      <td>-0.675918</td>\n",
              "      <td>-0.557193</td>\n",
              "      <td>-0.577498</td>\n",
              "      <td>-0.576562</td>\n",
              "      <td>-0.351032</td>\n",
              "      <td>-1.212886</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.637717</td>\n",
              "      <td>-0.566758</td>\n",
              "      <td>-0.560215</td>\n",
              "      <td>-1.243933</td>\n",
              "      <td>-0.498211</td>\n",
              "      <td>0.020448</td>\n",
              "      <td>-0.009939</td>\n",
              "      <td>-0.725731</td>\n",
              "      <td>-0.785298</td>\n",
              "      <td>-0.801400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-01 12:09:00</th>\n",
              "      <td>-1.285234</td>\n",
              "      <td>-0.438536</td>\n",
              "      <td>-0.233421</td>\n",
              "      <td>-0.223439</td>\n",
              "      <td>-0.674958</td>\n",
              "      <td>0.158355</td>\n",
              "      <td>0.163795</td>\n",
              "      <td>-0.573748</td>\n",
              "      <td>-0.943849</td>\n",
              "      <td>-0.826813</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.656439</td>\n",
              "      <td>-0.708313</td>\n",
              "      <td>-0.700189</td>\n",
              "      <td>-1.227854</td>\n",
              "      <td>-0.386283</td>\n",
              "      <td>-0.379819</td>\n",
              "      <td>-0.327183</td>\n",
              "      <td>-0.726256</td>\n",
              "      <td>0.127960</td>\n",
              "      <td>0.130166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-01 13:00:00</th>\n",
              "      <td>-1.330649</td>\n",
              "      <td>-1.042758</td>\n",
              "      <td>-0.836138</td>\n",
              "      <td>-0.352565</td>\n",
              "      <td>-0.110838</td>\n",
              "      <td>-0.832403</td>\n",
              "      <td>-0.863530</td>\n",
              "      <td>-0.607518</td>\n",
              "      <td>-0.953176</td>\n",
              "      <td>-0.367317</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.263616</td>\n",
              "      <td>-0.991423</td>\n",
              "      <td>-0.981247</td>\n",
              "      <td>-1.302887</td>\n",
              "      <td>-0.299948</td>\n",
              "      <td>-1.819765</td>\n",
              "      <td>-1.395900</td>\n",
              "      <td>-0.301729</td>\n",
              "      <td>-0.263436</td>\n",
              "      <td>-0.269550</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 35 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1889e7fd-a798-4da0-b14c-314afa317d20')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1889e7fd-a798-4da0-b14c-314afa317d20 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1889e7fd-a798-4da0-b14c-314afa317d20');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-10c62d4c-608c-4fcf-ba3e-d75afe171859\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-10c62d4c-608c-4fcf-ba3e-d75afe171859')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-10c62d4c-608c-4fcf-ba3e-d75afe171859 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Concatenate all ticker DataFrames\n",
        "df = pd.concat(ticker_data_frames, axis=1)\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "l_DDzDQp8Hju"
      },
      "outputs": [],
      "source": [
        "# Shift the df data to create labels\n",
        "labels = df.shift(-1)\n",
        "# Drop the last row in both percent_change_data and labels as it won't have a corresponding label\n",
        "df = df.iloc[:-1]\n",
        "labels = labels.iloc[:-1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "k0Jdnzly9FQ3"
      },
      "outputs": [],
      "source": [
        "# Sequence len = 24 means that we have 2 hours of 5 min data\n",
        "SEQUENCE_LEN = 24\n",
        "\n",
        "# Function to create X-day sequences for each ticker\n",
        "def create_sequences(data, labels, mean, std, sequence_length=SEQUENCE_LEN):\n",
        "    sequences = []\n",
        "    lab = []\n",
        "    data_size = len(data)\n",
        "\n",
        "    # + 12 because we want to predict the next hour\n",
        "    for i in range(data_size - (sequence_length + 13)):\n",
        "      if i == 0:\n",
        "        continue\n",
        "\n",
        "      sequences.append(data[i:i + sequence_length])\n",
        "      lab.append([labels[i], labels[i + 11], mean[0], std[0]])\n",
        "\n",
        "    return np.array(sequences), np.array(lab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "y4Mh2yj79Ud9"
      },
      "outputs": [],
      "source": [
        "sequences_dict = {}\n",
        "sequence_labels = {}\n",
        "for ticker in tickers:\n",
        "\n",
        "    # Extract close and volume data for the ticker\n",
        "    close = df[ticker+'_close'].values\n",
        "    width = df[ticker+'_width'].values\n",
        "    rsi = df[ticker+'_rsi'].values\n",
        "    roc = df[ticker+'_roc'].values\n",
        "    volume = df[ticker+'_volume'].values\n",
        "    diff = df[ticker+'_diff'].values\n",
        "    pct_change = df[ticker+'_percent_change_close'].values\n",
        "\n",
        "    # Combine close and volume data\n",
        "    ticker_data = np.column_stack((close,\n",
        "                                   width,\n",
        "                                   rsi,\n",
        "                                   roc,\n",
        "                                   volume,\n",
        "                                   diff,\n",
        "                                   pct_change))\n",
        "\n",
        "    # Generate sequences\n",
        "    attribute = ticker+\"_close\"\n",
        "    ticker_sequences, lab = create_sequences(ticker_data,\n",
        "                                             labels[attribute].values[SEQUENCE_LEN-1:],\n",
        "                                             stats[attribute+\"_mean\"].values,\n",
        "                                             stats[attribute+\"_std\"].values)\n",
        "\n",
        "    sequences_dict[ticker] = ticker_sequences\n",
        "    sequence_labels[ticker] = lab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "yRQ0zowW2zKF",
        "outputId": "51c87922-28df-48d7-fa96-109c8c8a687f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3007, 24, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "sequences_dict['META'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "nKbFo1mH2zKG",
        "outputId": "af7a9830-1811-4dbc-a7b9-7a81609c9a36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.4491237 , -0.7667115 ,  0.46745801,  0.29408539, -0.68041106,\n",
              "        0.26843901,  0.27930452])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "sequences_dict['META'][2][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "5mZZJmuS2zKG",
        "outputId": "ae9abf2b-0156-4298-b5b0-83f3e585aba5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3007, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "sequence_labels['META'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "XIl_sq4O2zKG",
        "outputId": "fadbcc12-f9cc-4f72-b368-75a1d9866efa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ -1.43925084,  -1.53008114, 181.8889262 ,   5.06438907])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "sequence_labels['META'][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "-oXY-sXP-fnZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a261aa8-52ac-43ab-fb31-3442f5a564b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_sequences.shape=(12025, 24, 7)\n",
            "train_labels.shape=(12025, 4)\n",
            "other_sequences.shape=(2890, 24, 7)\n",
            "other_labels.shape=(2890, 4)\n"
          ]
        }
      ],
      "source": [
        "# Combine data and labels from all tickers\n",
        "\n",
        "TRAIN_FRACTION = 0.8\n",
        "\n",
        "train_sequences = []\n",
        "train_labels = []\n",
        "other_sequences = []\n",
        "other_labels = []\n",
        "\n",
        "def extend_sequences(ticker):\n",
        "  ticker_sequence = sequences_dict[ticker]\n",
        "  ticker_labels = sequence_labels[ticker]\n",
        "  seq_len = len(ticker_sequence)\n",
        "  assert seq_len == len(ticker_labels)\n",
        "  train_len = int(seq_len * TRAIN_FRACTION)\n",
        "  train_sequences.extend(ticker_sequence[:train_len])\n",
        "  train_labels.extend(ticker_labels[:train_len])\n",
        "  other_sequences.extend(ticker_sequence[train_len + SEQUENCE_LEN:])\n",
        "  other_labels.extend(ticker_labels[train_len + SEQUENCE_LEN:])\n",
        "\n",
        "\n",
        "for ticker in tickers:\n",
        "    extend_sequences(ticker)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "train_sequences = np.array(train_sequences)\n",
        "train_labels = np.array(train_labels)\n",
        "other_sequences = np.array(other_sequences)\n",
        "other_labels = np.array(other_labels)\n",
        "\n",
        "print(f\"{train_sequences.shape=}\")\n",
        "print(f\"{train_labels.shape=}\")\n",
        "print(f\"{other_sequences.shape=}\")\n",
        "print(f\"{other_labels.shape=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "8QY42PaV-kPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f5c5c69-ba93-4e51-be2c-a1ad2f26ec54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation_sequences.shape=(1421, 24, 7)\n",
            "validation_labels.shape=(1421, 4)\n",
            "test_sequences.shape=(1421, 24, 7)\n",
            "test_labels.shape=(1421, 4)\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "# Randomize the order of the training data\n",
        "shuffled_indices = np.random.permutation(len(train_sequences))\n",
        "train_sequences = train_sequences[shuffled_indices]\n",
        "train_labels = train_labels[shuffled_indices]\n",
        "\n",
        "# Validation/Test split is 50/50\n",
        "# Need to leave gaps between the train, val, and test samples so they don't overlap in time.\n",
        "val_size = int(len(other_sequences) * 0.5)\n",
        "\n",
        "validation_sequences = other_sequences[SEQUENCE_LEN:val_size]\n",
        "validation_labels = other_labels[SEQUENCE_LEN:val_size]\n",
        "\n",
        "test_sequences = other_sequences[val_size + SEQUENCE_LEN:]\n",
        "test_labels = other_labels[val_size + SEQUENCE_LEN:]\n",
        "\n",
        "print(f\"{validation_sequences.shape=}\")\n",
        "print(f\"{validation_labels.shape=}\")\n",
        "print(f\"{test_sequences.shape=}\")\n",
        "print(f\"{test_labels.shape=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBKt-Fhj-p3w",
        "outputId": "fec35474-8f5a-4009-87db-0b566e5e08f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)        [(None, 24, 7)]              0         []                            \n",
            "                                                                                                  \n",
            " layer_normalization_100 (L  (None, 24, 7)                14        ['input_5[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_48 (M  (None, 24, 7)                126983    ['layer_normalization_100[0][0\n",
            " ultiHeadAttention)                                                 ]',                           \n",
            "                                                                     'layer_normalization_100[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_96 (Add)                (None, 24, 7)                0         ['multi_head_attention_48[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'input_5[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_101 (L  (None, 24, 7)                14        ['add_96[0][0]']              \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_100 (Dense)           (None, 24, 1024)             8192      ['layer_normalization_101[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_48 (Dropout)        (None, 24, 1024)             0         ['dense_100[0][0]']           \n",
            "                                                                                                  \n",
            " dense_101 (Dense)           (None, 24, 7)                7175      ['dropout_48[0][0]']          \n",
            "                                                                                                  \n",
            " add_97 (Add)                (None, 24, 7)                0         ['dense_101[0][0]',           \n",
            "                                                                     'add_96[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_102 (L  (None, 24, 7)                14        ['add_97[0][0]']              \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_49 (M  (None, 24, 7)                126983    ['layer_normalization_102[0][0\n",
            " ultiHeadAttention)                                                 ]',                           \n",
            "                                                                     'layer_normalization_102[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_98 (Add)                (None, 24, 7)                0         ['multi_head_attention_49[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_97[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_103 (L  (None, 24, 7)                14        ['add_98[0][0]']              \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_102 (Dense)           (None, 24, 1024)             8192      ['layer_normalization_103[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_49 (Dropout)        (None, 24, 1024)             0         ['dense_102[0][0]']           \n",
            "                                                                                                  \n",
            " dense_103 (Dense)           (None, 24, 7)                7175      ['dropout_49[0][0]']          \n",
            "                                                                                                  \n",
            " add_99 (Add)                (None, 24, 7)                0         ['dense_103[0][0]',           \n",
            "                                                                     'add_98[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_104 (L  (None, 24, 7)                14        ['add_99[0][0]']              \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_50 (M  (None, 24, 7)                126983    ['layer_normalization_104[0][0\n",
            " ultiHeadAttention)                                                 ]',                           \n",
            "                                                                     'layer_normalization_104[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_100 (Add)               (None, 24, 7)                0         ['multi_head_attention_50[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_99[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_105 (L  (None, 24, 7)                14        ['add_100[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_104 (Dense)           (None, 24, 1024)             8192      ['layer_normalization_105[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_50 (Dropout)        (None, 24, 1024)             0         ['dense_104[0][0]']           \n",
            "                                                                                                  \n",
            " dense_105 (Dense)           (None, 24, 7)                7175      ['dropout_50[0][0]']          \n",
            "                                                                                                  \n",
            " add_101 (Add)               (None, 24, 7)                0         ['dense_105[0][0]',           \n",
            "                                                                     'add_100[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_106 (L  (None, 24, 7)                14        ['add_101[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_51 (M  (None, 24, 7)                126983    ['layer_normalization_106[0][0\n",
            " ultiHeadAttention)                                                 ]',                           \n",
            "                                                                     'layer_normalization_106[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_102 (Add)               (None, 24, 7)                0         ['multi_head_attention_51[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_101[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_107 (L  (None, 24, 7)                14        ['add_102[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_106 (Dense)           (None, 24, 1024)             8192      ['layer_normalization_107[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_51 (Dropout)        (None, 24, 1024)             0         ['dense_106[0][0]']           \n",
            "                                                                                                  \n",
            " dense_107 (Dense)           (None, 24, 7)                7175      ['dropout_51[0][0]']          \n",
            "                                                                                                  \n",
            " add_103 (Add)               (None, 24, 7)                0         ['dense_107[0][0]',           \n",
            "                                                                     'add_102[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_108 (L  (None, 24, 7)                14        ['add_103[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_52 (M  (None, 24, 7)                126983    ['layer_normalization_108[0][0\n",
            " ultiHeadAttention)                                                 ]',                           \n",
            "                                                                     'layer_normalization_108[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_104 (Add)               (None, 24, 7)                0         ['multi_head_attention_52[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_103[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_109 (L  (None, 24, 7)                14        ['add_104[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_108 (Dense)           (None, 24, 1024)             8192      ['layer_normalization_109[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_52 (Dropout)        (None, 24, 1024)             0         ['dense_108[0][0]']           \n",
            "                                                                                                  \n",
            " dense_109 (Dense)           (None, 24, 7)                7175      ['dropout_52[0][0]']          \n",
            "                                                                                                  \n",
            " add_105 (Add)               (None, 24, 7)                0         ['dense_109[0][0]',           \n",
            "                                                                     'add_104[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_110 (L  (None, 24, 7)                14        ['add_105[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_53 (M  (None, 24, 7)                126983    ['layer_normalization_110[0][0\n",
            " ultiHeadAttention)                                                 ]',                           \n",
            "                                                                     'layer_normalization_110[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_106 (Add)               (None, 24, 7)                0         ['multi_head_attention_53[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_105[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_111 (L  (None, 24, 7)                14        ['add_106[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_110 (Dense)           (None, 24, 1024)             8192      ['layer_normalization_111[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_53 (Dropout)        (None, 24, 1024)             0         ['dense_110[0][0]']           \n",
            "                                                                                                  \n",
            " dense_111 (Dense)           (None, 24, 7)                7175      ['dropout_53[0][0]']          \n",
            "                                                                                                  \n",
            " add_107 (Add)               (None, 24, 7)                0         ['dense_111[0][0]',           \n",
            "                                                                     'add_106[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_112 (L  (None, 24, 7)                14        ['add_107[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_54 (M  (None, 24, 7)                126983    ['layer_normalization_112[0][0\n",
            " ultiHeadAttention)                                                 ]',                           \n",
            "                                                                     'layer_normalization_112[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_108 (Add)               (None, 24, 7)                0         ['multi_head_attention_54[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_107[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_113 (L  (None, 24, 7)                14        ['add_108[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_112 (Dense)           (None, 24, 1024)             8192      ['layer_normalization_113[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_54 (Dropout)        (None, 24, 1024)             0         ['dense_112[0][0]']           \n",
            "                                                                                                  \n",
            " dense_113 (Dense)           (None, 24, 7)                7175      ['dropout_54[0][0]']          \n",
            "                                                                                                  \n",
            " add_109 (Add)               (None, 24, 7)                0         ['dense_113[0][0]',           \n",
            "                                                                     'add_108[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_114 (L  (None, 24, 7)                14        ['add_109[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_55 (M  (None, 24, 7)                126983    ['layer_normalization_114[0][0\n",
            " ultiHeadAttention)                                                 ]',                           \n",
            "                                                                     'layer_normalization_114[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_110 (Add)               (None, 24, 7)                0         ['multi_head_attention_55[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_109[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_115 (L  (None, 24, 7)                14        ['add_110[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_114 (Dense)           (None, 24, 1024)             8192      ['layer_normalization_115[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_55 (Dropout)        (None, 24, 1024)             0         ['dense_114[0][0]']           \n",
            "                                                                                                  \n",
            " dense_115 (Dense)           (None, 24, 7)                7175      ['dropout_55[0][0]']          \n",
            "                                                                                                  \n",
            " add_111 (Add)               (None, 24, 7)                0         ['dense_115[0][0]',           \n",
            "                                                                     'add_110[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_116 (L  (None, 24, 7)                14        ['add_111[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_56 (M  (None, 24, 7)                126983    ['layer_normalization_116[0][0\n",
            " ultiHeadAttention)                                                 ]',                           \n",
            "                                                                     'layer_normalization_116[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_112 (Add)               (None, 24, 7)                0         ['multi_head_attention_56[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_111[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_117 (L  (None, 24, 7)                14        ['add_112[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_116 (Dense)           (None, 24, 1024)             8192      ['layer_normalization_117[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_56 (Dropout)        (None, 24, 1024)             0         ['dense_116[0][0]']           \n",
            "                                                                                                  \n",
            " dense_117 (Dense)           (None, 24, 7)                7175      ['dropout_56[0][0]']          \n",
            "                                                                                                  \n",
            " add_113 (Add)               (None, 24, 7)                0         ['dense_117[0][0]',           \n",
            "                                                                     'add_112[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_118 (L  (None, 24, 7)                14        ['add_113[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_57 (M  (None, 24, 7)                126983    ['layer_normalization_118[0][0\n",
            " ultiHeadAttention)                                                 ]',                           \n",
            "                                                                     'layer_normalization_118[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_114 (Add)               (None, 24, 7)                0         ['multi_head_attention_57[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_113[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_119 (L  (None, 24, 7)                14        ['add_114[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_118 (Dense)           (None, 24, 1024)             8192      ['layer_normalization_119[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_57 (Dropout)        (None, 24, 1024)             0         ['dense_118[0][0]']           \n",
            "                                                                                                  \n",
            " dense_119 (Dense)           (None, 24, 7)                7175      ['dropout_57[0][0]']          \n",
            "                                                                                                  \n",
            " add_115 (Add)               (None, 24, 7)                0         ['dense_119[0][0]',           \n",
            "                                                                     'add_114[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_120 (L  (None, 24, 7)                14        ['add_115[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_58 (M  (None, 24, 7)                126983    ['layer_normalization_120[0][0\n",
            " ultiHeadAttention)                                                 ]',                           \n",
            "                                                                     'layer_normalization_120[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_116 (Add)               (None, 24, 7)                0         ['multi_head_attention_58[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_115[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_121 (L  (None, 24, 7)                14        ['add_116[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_120 (Dense)           (None, 24, 1024)             8192      ['layer_normalization_121[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_58 (Dropout)        (None, 24, 1024)             0         ['dense_120[0][0]']           \n",
            "                                                                                                  \n",
            " dense_121 (Dense)           (None, 24, 7)                7175      ['dropout_58[0][0]']          \n",
            "                                                                                                  \n",
            " add_117 (Add)               (None, 24, 7)                0         ['dense_121[0][0]',           \n",
            "                                                                     'add_116[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_122 (L  (None, 24, 7)                14        ['add_117[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_59 (M  (None, 24, 7)                126983    ['layer_normalization_122[0][0\n",
            " ultiHeadAttention)                                                 ]',                           \n",
            "                                                                     'layer_normalization_122[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_118 (Add)               (None, 24, 7)                0         ['multi_head_attention_59[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_117[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_123 (L  (None, 24, 7)                14        ['add_118[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_122 (Dense)           (None, 24, 1024)             8192      ['layer_normalization_123[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_59 (Dropout)        (None, 24, 1024)             0         ['dense_122[0][0]']           \n",
            "                                                                                                  \n",
            " dense_123 (Dense)           (None, 24, 7)                7175      ['dropout_59[0][0]']          \n",
            "                                                                                                  \n",
            " add_119 (Add)               (None, 24, 7)                0         ['dense_123[0][0]',           \n",
            "                                                                     'add_118[0][0]']             \n",
            "                                                                                                  \n",
            " global_average_pooling1d_4  (None, 7)                    0         ['add_119[0][0]']             \n",
            "  (GlobalAveragePooling1D)                                                                        \n",
            "                                                                                                  \n",
            " layer_normalization_124 (L  (None, 7)                    14        ['global_average_pooling1d_4[0\n",
            " ayerNormalization)                                                 ][0]']                        \n",
            "                                                                                                  \n",
            " dense_124 (Dense)           (None, 1)                    8         ['layer_normalization_124[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1708558 (6.52 MB)\n",
            "Trainable params: 1708558 (6.52 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Attention and Normalization\n",
        "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
        "    x = Add()([x, inputs])\n",
        "\n",
        "    # Feed Forward Part\n",
        "    y = LayerNormalization(epsilon=1e-6)(x)\n",
        "    y = Dense(ff_dim, activation=\"relu\")(y)\n",
        "    y = Dropout(dropout)(y)\n",
        "    y = Dense(inputs.shape[-1])(y)\n",
        "    return Add()([y, x])\n",
        "\n",
        "def build_transformer_model(input_shape, head_size, num_heads, ff_dim, num_layers, dropout=0):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = inputs\n",
        "\n",
        "    # Create multiple layers of the Transformer block\n",
        "    for _ in range(num_layers):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    # Final part of the model\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "    x = LayerNormalization(epsilon=1e-6)(x)\n",
        "    outputs = Dense(1, activation=\"linear\")(x)\n",
        "\n",
        "    # Compile model\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Model parameters\n",
        "input_shape = train_sequences.shape[1:]\n",
        "head_size = 256\n",
        "num_heads = 16\n",
        "ff_dim = 1024\n",
        "num_layers = 12\n",
        "dropout = 0.20\n",
        "\n",
        "# Build the model\n",
        "model = build_transformer_model(input_shape, head_size, num_heads, ff_dim, num_layers, dropout)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "bWMOzku9-vpv"
      },
      "outputs": [],
      "source": [
        "def custom_mae_loss(y_true, y_pred):\n",
        "    y_true_next = tf.cast(y_true[:, 1], tf.float64)\n",
        "    y_pred_next = tf.cast(y_pred[:, 0], tf.float64)\n",
        "    abs_error = tf.abs(y_true_next - y_pred_next)\n",
        "\n",
        "    return tf.reduce_mean(abs_error)\n",
        "\n",
        "def dir_acc(y_true, y_pred):\n",
        "    mean, std = tf.cast(y_true[:, 2], tf.float64), tf.cast(y_true[:, 3], tf.float64)\n",
        "\n",
        "    y_true_prev = (tf.cast(y_true[:, 0], tf.float64) * std) + mean\n",
        "    y_true_next = (tf.cast(y_true[:, 1], tf.float64) * std) + mean\n",
        "    y_pred_next = (tf.cast(y_pred[:, 0], tf.float64) * std) + mean\n",
        "\n",
        "    true_change = y_true_next - y_true_prev\n",
        "    pred_change = y_pred_next - y_true_prev\n",
        "\n",
        "    correct_direction = tf.equal(tf.sign(true_change), tf.sign(pred_change))\n",
        "\n",
        "    return tf.reduce_mean(tf.cast(correct_direction, tf.float64))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "CQ20qXHdABEa"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model.compile(optimizer=optimizer, loss=custom_mae_loss, metrics=[dir_acc])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "1kVujFs0BQu8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Define a callback to save the best model\n",
        "checkpoint_callback_train = ModelCheckpoint(\n",
        "    \"transformer_train_model.keras\",  # Filepath to save the best model\n",
        "    monitor=\"dir_acc\",  #\"loss\",  # Metric to monitor\n",
        "    save_best_only=True,  # Save only the best model\n",
        "    mode=\"max\",  # Minimize the monitored metric\n",
        "    verbose=1,  # Display progress\n",
        ")\n",
        "\n",
        "# Define a callback to save the best model\n",
        "checkpoint_callback_val = ModelCheckpoint(\n",
        "    \"transformer_val_model.keras\",  # Filepath to save the best model\n",
        "    monitor=\"val_dir_acc\", #\"val_loss\",  # Metric to monitor\n",
        "    save_best_only=True,  # Save only the best model\n",
        "    mode=\"max\",  # Minimize the monitored metric\n",
        "    verbose=1,  # Display progress\n",
        ")\n",
        "\n",
        "def get_lr_callback(batch_size=16, mode='cos', epochs=500, plot=False):\n",
        "    lr_start, lr_max, lr_min = 0.0001, 0.005, 0.00001  # Adjust learning rate boundaries\n",
        "    lr_ramp_ep = int(0.30 * epochs)  # 30% of epochs for warm-up\n",
        "    lr_sus_ep = max(0, int(0.10 * epochs) - lr_ramp_ep)  # Optional sustain phase, adjust as needed\n",
        "\n",
        "    def lrfn(epoch):\n",
        "        if epoch < lr_ramp_ep:  # Warm-up phase\n",
        "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
        "        elif epoch < lr_ramp_ep + lr_sus_ep:  # Sustain phase at max learning rate\n",
        "            lr = lr_max\n",
        "        elif mode == 'cos':\n",
        "            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep, epoch - lr_ramp_ep - lr_sus_ep\n",
        "            phase = math.pi * decay_epoch_index / decay_total_epochs\n",
        "            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n",
        "        else:\n",
        "            lr = lr_min  # Default to minimum learning rate if mode is not recognized\n",
        "\n",
        "        return lr\n",
        "\n",
        "    if plot:  # Plot learning rate curve if plot is True\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Learning Rate')\n",
        "        plt.title('Learning Rate Scheduler')\n",
        "        plt.show()\n",
        "\n",
        "    return tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wwlX1n52zKI"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Mv3B5gvBeR-",
        "outputId": "07d3f336-c2d4-4f85-f1f9-1f032e7720be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 1/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2304 - dir_acc: 0.5264\n",
            "Epoch 1: dir_acc improved from -inf to 0.52636, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 1: val_dir_acc improved from -inf to 0.58628, saving model to transformer_val_model.keras\n",
            "188/188 [==============================] - 54s 110ms/step - loss: 0.2304 - dir_acc: 0.5264 - val_loss: 0.1908 - val_dir_acc: 0.5863 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.00026333333333333336.\n",
            "Epoch 2/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1990 - dir_acc: 0.5349\n",
            "Epoch 2: dir_acc improved from 0.52636 to 0.53492, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 2: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.1990 - dir_acc: 0.5349 - val_loss: 0.1582 - val_dir_acc: 0.5554 - lr: 2.6333e-04\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.00042666666666666667.\n",
            "Epoch 3/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1948 - dir_acc: 0.5388\n",
            "Epoch 3: dir_acc improved from 0.53492 to 0.53877, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 3: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.1948 - dir_acc: 0.5388 - val_loss: 0.1864 - val_dir_acc: 0.5666 - lr: 4.2667e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.00059.\n",
            "Epoch 4/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1859 - dir_acc: 0.5404\n",
            "Epoch 4: dir_acc improved from 0.53877 to 0.54045, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 4: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.1859 - dir_acc: 0.5404 - val_loss: 0.1557 - val_dir_acc: 0.5782 - lr: 5.9000e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0007533333333333334.\n",
            "Epoch 5/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1845 - dir_acc: 0.5459\n",
            "Epoch 5: dir_acc improved from 0.54045 to 0.54594, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 5: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.1845 - dir_acc: 0.5459 - val_loss: 0.2296 - val_dir_acc: 0.5306 - lr: 7.5333e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0009166666666666668.\n",
            "Epoch 6/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1727 - dir_acc: 0.5463\n",
            "Epoch 6: dir_acc improved from 0.54594 to 0.54631, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 6: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 97ms/step - loss: 0.1727 - dir_acc: 0.5463 - val_loss: 0.1610 - val_dir_acc: 0.5566 - lr: 9.1667e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.00108.\n",
            "Epoch 7/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1703 - dir_acc: 0.5603\n",
            "Epoch 7: dir_acc improved from 0.54631 to 0.56025, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 7: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 97ms/step - loss: 0.1703 - dir_acc: 0.5603 - val_loss: 0.1978 - val_dir_acc: 0.4999 - lr: 0.0011\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0012433333333333335.\n",
            "Epoch 8/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1640 - dir_acc: 0.5668\n",
            "Epoch 8: dir_acc improved from 0.56025 to 0.56685, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 8: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.1640 - dir_acc: 0.5668 - val_loss: 0.1748 - val_dir_acc: 0.5423 - lr: 0.0012\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0014066666666666667.\n",
            "Epoch 9/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1557 - dir_acc: 0.5750\n",
            "Epoch 9: dir_acc improved from 0.56685 to 0.57503, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 9: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.1557 - dir_acc: 0.5750 - val_loss: 0.1790 - val_dir_acc: 0.5559 - lr: 0.0014\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.00157.\n",
            "Epoch 10/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1643 - dir_acc: 0.5728\n",
            "Epoch 10: dir_acc did not improve from 0.57503\n",
            "\n",
            "Epoch 10: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.1643 - dir_acc: 0.5728 - val_loss: 0.2054 - val_dir_acc: 0.5619 - lr: 0.0016\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.0017333333333333335.\n",
            "Epoch 11/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1595 - dir_acc: 0.5790\n",
            "Epoch 11: dir_acc improved from 0.57503 to 0.57898, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 11: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.1595 - dir_acc: 0.5790 - val_loss: 0.2498 - val_dir_acc: 0.5215 - lr: 0.0017\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.0018966666666666667.\n",
            "Epoch 12/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1519 - dir_acc: 0.5843\n",
            "Epoch 12: dir_acc improved from 0.57898 to 0.58430, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 12: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.1519 - dir_acc: 0.5843 - val_loss: 0.1984 - val_dir_acc: 0.5208 - lr: 0.0019\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.0020599999999999998.\n",
            "Epoch 13/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1588 - dir_acc: 0.5736\n",
            "Epoch 13: dir_acc did not improve from 0.58430\n",
            "\n",
            "Epoch 13: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 93ms/step - loss: 0.1588 - dir_acc: 0.5736 - val_loss: 0.2069 - val_dir_acc: 0.5430 - lr: 0.0021\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.0022233333333333332.\n",
            "Epoch 14/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1507 - dir_acc: 0.5964\n",
            "Epoch 14: dir_acc improved from 0.58430 to 0.59635, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 14: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.1507 - dir_acc: 0.5964 - val_loss: 0.1726 - val_dir_acc: 0.5109 - lr: 0.0022\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.0023866666666666667.\n",
            "Epoch 15/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1438 - dir_acc: 0.5988\n",
            "Epoch 15: dir_acc improved from 0.59635 to 0.59878, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 15: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.1438 - dir_acc: 0.5988 - val_loss: 0.1891 - val_dir_acc: 0.5152 - lr: 0.0024\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.0025499999999999997.\n",
            "Epoch 16/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1467 - dir_acc: 0.5943\n",
            "Epoch 16: dir_acc did not improve from 0.59878\n",
            "\n",
            "Epoch 16: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 94ms/step - loss: 0.1467 - dir_acc: 0.5943 - val_loss: 0.1646 - val_dir_acc: 0.5207 - lr: 0.0026\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.0027133333333333332.\n",
            "Epoch 17/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1429 - dir_acc: 0.5983\n",
            "Epoch 17: dir_acc did not improve from 0.59878\n",
            "\n",
            "Epoch 17: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 93ms/step - loss: 0.1429 - dir_acc: 0.5983 - val_loss: 0.2238 - val_dir_acc: 0.5275 - lr: 0.0027\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.0028766666666666667.\n",
            "Epoch 18/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1431 - dir_acc: 0.6057\n",
            "Epoch 18: dir_acc improved from 0.59878 to 0.60568, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 18: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.1431 - dir_acc: 0.6057 - val_loss: 0.1756 - val_dir_acc: 0.5403 - lr: 0.0029\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.0030399999999999997.\n",
            "Epoch 19/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1416 - dir_acc: 0.6079\n",
            "Epoch 19: dir_acc improved from 0.60568 to 0.60793, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 19: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.1416 - dir_acc: 0.6079 - val_loss: 0.1942 - val_dir_acc: 0.4963 - lr: 0.0030\n",
            "\n",
            "Epoch 20: LearningRateScheduler setting learning rate to 0.003203333333333333.\n",
            "Epoch 20/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1419 - dir_acc: 0.6064\n",
            "Epoch 20: dir_acc did not improve from 0.60793\n",
            "\n",
            "Epoch 20: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 93ms/step - loss: 0.1419 - dir_acc: 0.6064 - val_loss: 0.1936 - val_dir_acc: 0.5057 - lr: 0.0032\n",
            "\n",
            "Epoch 21: LearningRateScheduler setting learning rate to 0.0033666666666666667.\n",
            "Epoch 21/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1503 - dir_acc: 0.6059\n",
            "Epoch 21: dir_acc did not improve from 0.60793\n",
            "\n",
            "Epoch 21: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 93ms/step - loss: 0.1503 - dir_acc: 0.6059 - val_loss: 0.2234 - val_dir_acc: 0.5206 - lr: 0.0034\n",
            "\n",
            "Epoch 22: LearningRateScheduler setting learning rate to 0.0035299999999999997.\n",
            "Epoch 22/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1408 - dir_acc: 0.6162\n",
            "Epoch 22: dir_acc improved from 0.60793 to 0.61625, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 22: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.1408 - dir_acc: 0.6162 - val_loss: 0.1995 - val_dir_acc: 0.5112 - lr: 0.0035\n",
            "\n",
            "Epoch 23: LearningRateScheduler setting learning rate to 0.003693333333333333.\n",
            "Epoch 23/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1384 - dir_acc: 0.6142\n",
            "Epoch 23: dir_acc did not improve from 0.61625\n",
            "\n",
            "Epoch 23: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.1384 - dir_acc: 0.6142 - val_loss: 0.1913 - val_dir_acc: 0.5207 - lr: 0.0037\n",
            "\n",
            "Epoch 24: LearningRateScheduler setting learning rate to 0.0038566666666666667.\n",
            "Epoch 24/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1388 - dir_acc: 0.6205\n",
            "Epoch 24: dir_acc improved from 0.61625 to 0.62051, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 24: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.1388 - dir_acc: 0.6205 - val_loss: 0.1895 - val_dir_acc: 0.5396 - lr: 0.0039\n",
            "\n",
            "Epoch 25: LearningRateScheduler setting learning rate to 0.00402.\n",
            "Epoch 25/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1439 - dir_acc: 0.6038\n",
            "Epoch 25: dir_acc did not improve from 0.62051\n",
            "\n",
            "Epoch 25: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.1439 - dir_acc: 0.6038 - val_loss: 0.1806 - val_dir_acc: 0.5221 - lr: 0.0040\n",
            "\n",
            "Epoch 26: LearningRateScheduler setting learning rate to 0.004183333333333334.\n",
            "Epoch 26/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1387 - dir_acc: 0.6258\n",
            "Epoch 26: dir_acc improved from 0.62051 to 0.62580, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 26: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.1387 - dir_acc: 0.6258 - val_loss: 0.1833 - val_dir_acc: 0.5307 - lr: 0.0042\n",
            "\n",
            "Epoch 27: LearningRateScheduler setting learning rate to 0.004346666666666667.\n",
            "Epoch 27/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1335 - dir_acc: 0.6243\n",
            "Epoch 27: dir_acc did not improve from 0.62580\n",
            "\n",
            "Epoch 27: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.1335 - dir_acc: 0.6243 - val_loss: 0.2044 - val_dir_acc: 0.5322 - lr: 0.0043\n",
            "\n",
            "Epoch 28: LearningRateScheduler setting learning rate to 0.00451.\n",
            "Epoch 28/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1372 - dir_acc: 0.6205\n",
            "Epoch 28: dir_acc did not improve from 0.62580\n",
            "\n",
            "Epoch 28: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.1372 - dir_acc: 0.6205 - val_loss: 0.1779 - val_dir_acc: 0.5429 - lr: 0.0045\n",
            "\n",
            "Epoch 29: LearningRateScheduler setting learning rate to 0.004673333333333334.\n",
            "Epoch 29/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1346 - dir_acc: 0.6264\n",
            "Epoch 29: dir_acc improved from 0.62580 to 0.62643, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 29: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.1346 - dir_acc: 0.6264 - val_loss: 0.2117 - val_dir_acc: 0.5227 - lr: 0.0047\n",
            "\n",
            "Epoch 30: LearningRateScheduler setting learning rate to 0.004836666666666667.\n",
            "Epoch 30/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1298 - dir_acc: 0.6314\n",
            "Epoch 30: dir_acc improved from 0.62643 to 0.63136, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 30: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.1298 - dir_acc: 0.6314 - val_loss: 0.1808 - val_dir_acc: 0.5071 - lr: 0.0048\n",
            "\n",
            "Epoch 31: LearningRateScheduler setting learning rate to 0.005.\n",
            "Epoch 31/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1322 - dir_acc: 0.6309\n",
            "Epoch 31: dir_acc did not improve from 0.63136\n",
            "\n",
            "Epoch 31: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.1322 - dir_acc: 0.6309 - val_loss: 0.1898 - val_dir_acc: 0.5125 - lr: 0.0050\n",
            "\n",
            "Epoch 32: LearningRateScheduler setting learning rate to 0.00499748770102058.\n",
            "Epoch 32/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1325 - dir_acc: 0.6286\n",
            "Epoch 32: dir_acc did not improve from 0.63136\n",
            "\n",
            "Epoch 32: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.1325 - dir_acc: 0.6286 - val_loss: 0.1849 - val_dir_acc: 0.5645 - lr: 0.0050\n",
            "\n",
            "Epoch 33: LearningRateScheduler setting learning rate to 0.0049899558635181215.\n",
            "Epoch 33/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1296 - dir_acc: 0.6381\n",
            "Epoch 33: dir_acc improved from 0.63136 to 0.63810, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 33: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.1296 - dir_acc: 0.6381 - val_loss: 0.1812 - val_dir_acc: 0.5159 - lr: 0.0050\n",
            "\n",
            "Epoch 34: LearningRateScheduler setting learning rate to 0.004977419655610997.\n",
            "Epoch 34/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1297 - dir_acc: 0.6317\n",
            "Epoch 34: dir_acc did not improve from 0.63810\n",
            "\n",
            "Epoch 34: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.1297 - dir_acc: 0.6317 - val_loss: 0.1882 - val_dir_acc: 0.5442 - lr: 0.0050\n",
            "\n",
            "Epoch 35: LearningRateScheduler setting learning rate to 0.004959904323553581.\n",
            "Epoch 35/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1268 - dir_acc: 0.6320\n",
            "Epoch 35: dir_acc did not improve from 0.63810\n",
            "\n",
            "Epoch 35: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.1268 - dir_acc: 0.6320 - val_loss: 0.1809 - val_dir_acc: 0.5187 - lr: 0.0050\n",
            "\n",
            "Epoch 36: LearningRateScheduler setting learning rate to 0.0049374451408936496.\n",
            "Epoch 36/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1240 - dir_acc: 0.6385\n",
            "Epoch 36: dir_acc improved from 0.63810 to 0.63854, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 36: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.1240 - dir_acc: 0.6385 - val_loss: 0.1801 - val_dir_acc: 0.5367 - lr: 0.0049\n",
            "\n",
            "Epoch 37: LearningRateScheduler setting learning rate to 0.004910087337436154.\n",
            "Epoch 37/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1204 - dir_acc: 0.6439\n",
            "Epoch 37: dir_acc improved from 0.63854 to 0.64389, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 37: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.1204 - dir_acc: 0.6439 - val_loss: 0.2126 - val_dir_acc: 0.5203 - lr: 0.0049\n",
            "\n",
            "Epoch 38: LearningRateScheduler setting learning rate to 0.004877886008156408.\n",
            "Epoch 38/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1258 - dir_acc: 0.6346\n",
            "Epoch 38: dir_acc did not improve from 0.64389\n",
            "\n",
            "Epoch 38: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.1258 - dir_acc: 0.6346 - val_loss: 0.1853 - val_dir_acc: 0.5429 - lr: 0.0049\n",
            "\n",
            "Epoch 39: LearningRateScheduler setting learning rate to 0.004840906002246144.\n",
            "Epoch 39/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1194 - dir_acc: 0.6399\n",
            "Epoch 39: dir_acc did not improve from 0.64389\n",
            "\n",
            "Epoch 39: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.1194 - dir_acc: 0.6399 - val_loss: 0.1986 - val_dir_acc: 0.5212 - lr: 0.0048\n",
            "\n",
            "Epoch 40: LearningRateScheduler setting learning rate to 0.00479922179251587.\n",
            "Epoch 40/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1202 - dir_acc: 0.6410\n",
            "Epoch 40: dir_acc did not improve from 0.64389\n",
            "\n",
            "Epoch 40: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.1202 - dir_acc: 0.6410 - val_loss: 0.1921 - val_dir_acc: 0.5119 - lr: 0.0048\n",
            "\n",
            "Epoch 41: LearningRateScheduler setting learning rate to 0.0047529173254165355.\n",
            "Epoch 41/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1199 - dir_acc: 0.6413\n",
            "Epoch 41: dir_acc did not improve from 0.64389\n",
            "\n",
            "Epoch 41: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.1199 - dir_acc: 0.6413 - val_loss: 0.2013 - val_dir_acc: 0.5306 - lr: 0.0048\n",
            "\n",
            "Epoch 42: LearningRateScheduler setting learning rate to 0.004702085851982562.\n",
            "Epoch 42/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1184 - dir_acc: 0.6464\n",
            "Epoch 42: dir_acc improved from 0.64389 to 0.64644, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 42: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.1184 - dir_acc: 0.6464 - val_loss: 0.2006 - val_dir_acc: 0.5348 - lr: 0.0047\n",
            "\n",
            "Epoch 43: LearningRateScheduler setting learning rate to 0.004646829740036656.\n",
            "Epoch 43/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1189 - dir_acc: 0.6480\n",
            "Epoch 43: dir_acc improved from 0.64644 to 0.64796, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 43: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.1189 - dir_acc: 0.6480 - val_loss: 0.1851 - val_dir_acc: 0.5057 - lr: 0.0046\n",
            "\n",
            "Epoch 44: LearningRateScheduler setting learning rate to 0.00458726026803465.\n",
            "Epoch 44/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1143 - dir_acc: 0.6568\n",
            "Epoch 44: dir_acc improved from 0.64796 to 0.65684, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 44: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.1143 - dir_acc: 0.6568 - val_loss: 0.1921 - val_dir_acc: 0.5227 - lr: 0.0046\n",
            "\n",
            "Epoch 45: LearningRateScheduler setting learning rate to 0.004523497400965494.\n",
            "Epoch 45/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1128 - dir_acc: 0.6564\n",
            "Epoch 45: dir_acc did not improve from 0.65684\n",
            "\n",
            "Epoch 45: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.1128 - dir_acc: 0.6564 - val_loss: 0.1843 - val_dir_acc: 0.5165 - lr: 0.0045\n",
            "\n",
            "Epoch 46: LearningRateScheduler setting learning rate to 0.004455669548757734.\n",
            "Epoch 46/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1159 - dir_acc: 0.6515\n",
            "Epoch 46: dir_acc did not improve from 0.65684\n",
            "\n",
            "Epoch 46: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.1159 - dir_acc: 0.6515 - val_loss: 0.1902 - val_dir_acc: 0.4988 - lr: 0.0045\n",
            "\n",
            "Epoch 47: LearningRateScheduler setting learning rate to 0.00438391330767901.\n",
            "Epoch 47/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1148 - dir_acc: 0.6529\n",
            "Epoch 47: dir_acc did not improve from 0.65684\n",
            "\n",
            "Epoch 47: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.1148 - dir_acc: 0.6529 - val_loss: 0.1909 - val_dir_acc: 0.5353 - lr: 0.0044\n",
            "\n",
            "Epoch 48: LearningRateScheduler setting learning rate to 0.004308373185249342.\n",
            "Epoch 48/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1106 - dir_acc: 0.6618\n",
            "Epoch 48: dir_acc improved from 0.65684 to 0.66177, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 48: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.1106 - dir_acc: 0.6618 - val_loss: 0.1810 - val_dir_acc: 0.5503 - lr: 0.0043\n",
            "\n",
            "Epoch 49: LearningRateScheduler setting learning rate to 0.004229201309222228.\n",
            "Epoch 49/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1086 - dir_acc: 0.6655\n",
            "Epoch 49: dir_acc improved from 0.66177 to 0.66548, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 49: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.1086 - dir_acc: 0.6655 - val_loss: 0.1821 - val_dir_acc: 0.5395 - lr: 0.0042\n",
            "\n",
            "Epoch 50: LearningRateScheduler setting learning rate to 0.0041465571212195825.\n",
            "Epoch 50/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1102 - dir_acc: 0.6679\n",
            "Epoch 50: dir_acc improved from 0.66548 to 0.66794, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 50: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.1102 - dir_acc: 0.6679 - val_loss: 0.1849 - val_dir_acc: 0.5034 - lr: 0.0041\n",
            "\n",
            "Epoch 51: LearningRateScheduler setting learning rate to 0.0040606070556375405.\n",
            "Epoch 51/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1082 - dir_acc: 0.6665\n",
            "Epoch 51: dir_acc did not improve from 0.66794\n",
            "\n",
            "Epoch 51: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.1082 - dir_acc: 0.6665 - val_loss: 0.1839 - val_dir_acc: 0.5418 - lr: 0.0041\n",
            "\n",
            "Epoch 52: LearningRateScheduler setting learning rate to 0.00397152420446972.\n",
            "Epoch 52/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1070 - dir_acc: 0.6682\n",
            "Epoch 52: dir_acc improved from 0.66794 to 0.66822, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 52: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.1070 - dir_acc: 0.6682 - val_loss: 0.1922 - val_dir_acc: 0.5275 - lr: 0.0040\n",
            "\n",
            "Epoch 53: LearningRateScheduler setting learning rate to 0.0038794879687229964.\n",
            "Epoch 53/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1057 - dir_acc: 0.6684\n",
            "Epoch 53: dir_acc improved from 0.66822 to 0.66836, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 53: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.1057 - dir_acc: 0.6684 - val_loss: 0.1837 - val_dir_acc: 0.5516 - lr: 0.0039\n",
            "\n",
            "Epoch 54: LearningRateScheduler setting learning rate to 0.0037846836971277367.\n",
            "Epoch 54/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1067 - dir_acc: 0.6708\n",
            "Epoch 54: dir_acc improved from 0.66836 to 0.67079, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 54: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.1067 - dir_acc: 0.6708 - val_loss: 0.1844 - val_dir_acc: 0.5286 - lr: 0.0038\n",
            "\n",
            "Epoch 55: LearningRateScheduler setting learning rate to 0.003687302312870132.\n",
            "Epoch 55/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1027 - dir_acc: 0.6772\n",
            "Epoch 55: dir_acc improved from 0.67079 to 0.67721, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 55: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.1027 - dir_acc: 0.6772 - val_loss: 0.2095 - val_dir_acc: 0.5510 - lr: 0.0037\n",
            "\n",
            "Epoch 56: LearningRateScheduler setting learning rate to 0.0035875399290983077.\n",
            "Epoch 56/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1031 - dir_acc: 0.6770\n",
            "Epoch 56: dir_acc did not improve from 0.67721\n",
            "\n",
            "Epoch 56: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.1031 - dir_acc: 0.6770 - val_loss: 0.2210 - val_dir_acc: 0.5281 - lr: 0.0036\n",
            "\n",
            "Epoch 57: LearningRateScheduler setting learning rate to 0.00348559745397654.\n",
            "Epoch 57/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1030 - dir_acc: 0.6736\n",
            "Epoch 57: dir_acc did not improve from 0.67721\n",
            "\n",
            "Epoch 57: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 93ms/step - loss: 0.1030 - dir_acc: 0.6736 - val_loss: 0.2017 - val_dir_acc: 0.5308 - lr: 0.0035\n",
            "\n",
            "Epoch 58: LearningRateScheduler setting learning rate to 0.0033816801860829505.\n",
            "Epoch 58/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0993 - dir_acc: 0.6812\n",
            "Epoch 58: dir_acc improved from 0.67721 to 0.68116, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 58: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.0993 - dir_acc: 0.6812 - val_loss: 0.1825 - val_dir_acc: 0.5362 - lr: 0.0034\n",
            "\n",
            "Epoch 59: LearningRateScheduler setting learning rate to 0.0032759974009654944.\n",
            "Epoch 59/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1014 - dir_acc: 0.6828\n",
            "Epoch 59: dir_acc improved from 0.68116 to 0.68279, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 59: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.1014 - dir_acc: 0.6828 - val_loss: 0.1876 - val_dir_acc: 0.5239 - lr: 0.0033\n",
            "\n",
            "Epoch 60: LearningRateScheduler setting learning rate to 0.0031687619296888545.\n",
            "Epoch 60/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0972 - dir_acc: 0.6908\n",
            "Epoch 60: dir_acc improved from 0.68279 to 0.69083, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 60: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.0972 - dir_acc: 0.6908 - val_loss: 0.1837 - val_dir_acc: 0.5449 - lr: 0.0032\n",
            "\n",
            "Epoch 61: LearningRateScheduler setting learning rate to 0.003060189730221005.\n",
            "Epoch 61/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0987 - dir_acc: 0.6842\n",
            "Epoch 61: dir_acc did not improve from 0.69083\n",
            "\n",
            "Epoch 61: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.0987 - dir_acc: 0.6842 - val_loss: 0.1894 - val_dir_acc: 0.5367 - lr: 0.0031\n",
            "\n",
            "Epoch 62: LearningRateScheduler setting learning rate to 0.002950499452522599.\n",
            "Epoch 62/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0985 - dir_acc: 0.6875\n",
            "Epoch 62: dir_acc did not improve from 0.69083\n",
            "\n",
            "Epoch 62: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 93ms/step - loss: 0.0985 - dir_acc: 0.6875 - val_loss: 0.1803 - val_dir_acc: 0.5592 - lr: 0.0030\n",
            "\n",
            "Epoch 63: LearningRateScheduler setting learning rate to 0.0028399119982150506.\n",
            "Epoch 63/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0968 - dir_acc: 0.6908\n",
            "Epoch 63: dir_acc did not improve from 0.69083\n",
            "\n",
            "Epoch 63: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 93ms/step - loss: 0.0968 - dir_acc: 0.6908 - val_loss: 0.1933 - val_dir_acc: 0.5234 - lr: 0.0028\n",
            "\n",
            "Epoch 64: LearningRateScheduler setting learning rate to 0.002728650075714067.\n",
            "Epoch 64/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0939 - dir_acc: 0.6995\n",
            "Epoch 64: dir_acc improved from 0.69083 to 0.69951, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 64: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.0939 - dir_acc: 0.6995 - val_loss: 0.1767 - val_dir_acc: 0.5286 - lr: 0.0027\n",
            "\n",
            "Epoch 65: LearningRateScheduler setting learning rate to 0.0026169377517245352.\n",
            "Epoch 65/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0946 - dir_acc: 0.6974\n",
            "Epoch 65: dir_acc did not improve from 0.69951\n",
            "\n",
            "Epoch 65: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.0946 - dir_acc: 0.6974 - val_loss: 0.1816 - val_dir_acc: 0.5353 - lr: 0.0026\n",
            "\n",
            "Epoch 66: LearningRateScheduler setting learning rate to 0.0025050000000000003.\n",
            "Epoch 66/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0924 - dir_acc: 0.6979\n",
            "Epoch 66: dir_acc did not improve from 0.69951\n",
            "\n",
            "Epoch 66: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.0924 - dir_acc: 0.6979 - val_loss: 0.1842 - val_dir_acc: 0.5442 - lr: 0.0025\n",
            "\n",
            "Epoch 67: LearningRateScheduler setting learning rate to 0.0023930622482754658.\n",
            "Epoch 67/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0896 - dir_acc: 0.7049\n",
            "Epoch 67: dir_acc improved from 0.69951 to 0.70494, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 67: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.0896 - dir_acc: 0.7049 - val_loss: 0.1888 - val_dir_acc: 0.5605 - lr: 0.0024\n",
            "\n",
            "Epoch 68: LearningRateScheduler setting learning rate to 0.002281349924285934.\n",
            "Epoch 68/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0897 - dir_acc: 0.7094\n",
            "Epoch 68: dir_acc improved from 0.70494 to 0.70938, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 68: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.0897 - dir_acc: 0.7094 - val_loss: 0.1876 - val_dir_acc: 0.5591 - lr: 0.0023\n",
            "\n",
            "Epoch 69: LearningRateScheduler setting learning rate to 0.00217008800178495.\n",
            "Epoch 69/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0897 - dir_acc: 0.7045\n",
            "Epoch 69: dir_acc did not improve from 0.70938\n",
            "\n",
            "Epoch 69: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.0897 - dir_acc: 0.7045 - val_loss: 0.1904 - val_dir_acc: 0.5380 - lr: 0.0022\n",
            "\n",
            "Epoch 70: LearningRateScheduler setting learning rate to 0.002059500547477402.\n",
            "Epoch 70/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0885 - dir_acc: 0.7050\n",
            "Epoch 70: dir_acc did not improve from 0.70938\n",
            "\n",
            "Epoch 70: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.0885 - dir_acc: 0.7050 - val_loss: 0.1872 - val_dir_acc: 0.5571 - lr: 0.0021\n",
            "\n",
            "Epoch 71: LearningRateScheduler setting learning rate to 0.001949810269778996.\n",
            "Epoch 71/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0873 - dir_acc: 0.7154\n",
            "Epoch 71: dir_acc improved from 0.70938 to 0.71537, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 71: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.0873 - dir_acc: 0.7154 - val_loss: 0.1951 - val_dir_acc: 0.5327 - lr: 0.0019\n",
            "\n",
            "Epoch 72: LearningRateScheduler setting learning rate to 0.0018412380703111465.\n",
            "Epoch 72/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0848 - dir_acc: 0.7194\n",
            "Epoch 72: dir_acc improved from 0.71537 to 0.71943, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 72: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.0848 - dir_acc: 0.7194 - val_loss: 0.1881 - val_dir_acc: 0.5367 - lr: 0.0018\n",
            "\n",
            "Epoch 73: LearningRateScheduler setting learning rate to 0.0017340025990345066.\n",
            "Epoch 73/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0849 - dir_acc: 0.7162\n",
            "Epoch 73: dir_acc did not improve from 0.71943\n",
            "\n",
            "Epoch 73: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.0849 - dir_acc: 0.7162 - val_loss: 0.1860 - val_dir_acc: 0.5435 - lr: 0.0017\n",
            "\n",
            "Epoch 74: LearningRateScheduler setting learning rate to 0.0016283198139170505.\n",
            "Epoch 74/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0835 - dir_acc: 0.7193\n",
            "Epoch 74: dir_acc did not improve from 0.71943\n",
            "\n",
            "Epoch 74: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.0835 - dir_acc: 0.7193 - val_loss: 0.1919 - val_dir_acc: 0.5470 - lr: 0.0016\n",
            "\n",
            "Epoch 75: LearningRateScheduler setting learning rate to 0.0015244025460234615.\n",
            "Epoch 75/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0829 - dir_acc: 0.7199\n",
            "Epoch 75: dir_acc improved from 0.71943 to 0.71987, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 75: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.0829 - dir_acc: 0.7199 - val_loss: 0.1804 - val_dir_acc: 0.5571 - lr: 0.0015\n",
            "\n",
            "Epoch 76: LearningRateScheduler setting learning rate to 0.001422460070901693.\n",
            "Epoch 76/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0832 - dir_acc: 0.7176\n",
            "Epoch 76: dir_acc did not improve from 0.71987\n",
            "\n",
            "Epoch 76: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.0832 - dir_acc: 0.7176 - val_loss: 0.1897 - val_dir_acc: 0.5761 - lr: 0.0014\n",
            "\n",
            "Epoch 77: LearningRateScheduler setting learning rate to 0.0013226976871298685.\n",
            "Epoch 77/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0822 - dir_acc: 0.7224\n",
            "Epoch 77: dir_acc improved from 0.71987 to 0.72238, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 77: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.0822 - dir_acc: 0.7224 - val_loss: 0.1830 - val_dir_acc: 0.5660 - lr: 0.0013\n",
            "\n",
            "Epoch 78: LearningRateScheduler setting learning rate to 0.0012253163028722645.\n",
            "Epoch 78/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0805 - dir_acc: 0.7281\n",
            "Epoch 78: dir_acc improved from 0.72238 to 0.72807, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 78: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.0805 - dir_acc: 0.7281 - val_loss: 0.1809 - val_dir_acc: 0.5342 - lr: 0.0012\n",
            "\n",
            "Epoch 79: LearningRateScheduler setting learning rate to 0.0011305120312770046.\n",
            "Epoch 79/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0796 - dir_acc: 0.7311\n",
            "Epoch 79: dir_acc improved from 0.72807 to 0.73106, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 79: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.0796 - dir_acc: 0.7311 - val_loss: 0.1792 - val_dir_acc: 0.5496 - lr: 0.0011\n",
            "\n",
            "Epoch 80: LearningRateScheduler setting learning rate to 0.00103847579553028.\n",
            "Epoch 80/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0784 - dir_acc: 0.7329\n",
            "Epoch 80: dir_acc improved from 0.73106 to 0.73290, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 80: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.0784 - dir_acc: 0.7329 - val_loss: 0.1846 - val_dir_acc: 0.5240 - lr: 0.0010\n",
            "\n",
            "Epoch 81: LearningRateScheduler setting learning rate to 0.00094939294436246.\n",
            "Epoch 81/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0783 - dir_acc: 0.7338\n",
            "Epoch 81: dir_acc improved from 0.73290 to 0.73379, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 81: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.0783 - dir_acc: 0.7338 - val_loss: 0.1772 - val_dir_acc: 0.5328 - lr: 9.4939e-04\n",
            "\n",
            "Epoch 82: LearningRateScheduler setting learning rate to 0.0008634428787804172.\n",
            "Epoch 82/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0769 - dir_acc: 0.7331\n",
            "Epoch 82: dir_acc did not improve from 0.73379\n",
            "\n",
            "Epoch 82: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.0769 - dir_acc: 0.7331 - val_loss: 0.1866 - val_dir_acc: 0.5421 - lr: 8.6344e-04\n",
            "\n",
            "Epoch 83: LearningRateScheduler setting learning rate to 0.0007807986907777728.\n",
            "Epoch 83/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0771 - dir_acc: 0.7377\n",
            "Epoch 83: dir_acc improved from 0.73379 to 0.73774, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 83: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.0771 - dir_acc: 0.7377 - val_loss: 0.1901 - val_dir_acc: 0.5342 - lr: 7.8080e-04\n",
            "\n",
            "Epoch 84: LearningRateScheduler setting learning rate to 0.0007016268147506584.\n",
            "Epoch 84/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0765 - dir_acc: 0.7427\n",
            "Epoch 84: dir_acc improved from 0.73774 to 0.74266, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 84: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.0765 - dir_acc: 0.7427 - val_loss: 0.1834 - val_dir_acc: 0.5383 - lr: 7.0163e-04\n",
            "\n",
            "Epoch 85: LearningRateScheduler setting learning rate to 0.000626086692320991.\n",
            "Epoch 85/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0753 - dir_acc: 0.7378\n",
            "Epoch 85: dir_acc did not improve from 0.74266\n",
            "\n",
            "Epoch 85: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.0753 - dir_acc: 0.7378 - val_loss: 0.1811 - val_dir_acc: 0.5476 - lr: 6.2609e-04\n",
            "\n",
            "Epoch 86: LearningRateScheduler setting learning rate to 0.0005543304512422657.\n",
            "Epoch 86/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0744 - dir_acc: 0.7409\n",
            "Epoch 86: dir_acc did not improve from 0.74266\n",
            "\n",
            "Epoch 86: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.0744 - dir_acc: 0.7409 - val_loss: 0.1804 - val_dir_acc: 0.5639 - lr: 5.5433e-04\n",
            "\n",
            "Epoch 87: LearningRateScheduler setting learning rate to 0.00048650259903450645.\n",
            "Epoch 87/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0738 - dir_acc: 0.7437\n",
            "Epoch 87: dir_acc improved from 0.74266 to 0.74371, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 87: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.0738 - dir_acc: 0.7437 - val_loss: 0.1789 - val_dir_acc: 0.5632 - lr: 4.8650e-04\n",
            "\n",
            "Epoch 88: LearningRateScheduler setting learning rate to 0.00042273973196535.\n",
            "Epoch 88/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0737 - dir_acc: 0.7441\n",
            "Epoch 88: dir_acc improved from 0.74371 to 0.74411, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 88: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.0737 - dir_acc: 0.7441 - val_loss: 0.1827 - val_dir_acc: 0.5383 - lr: 4.2274e-04\n",
            "\n",
            "Epoch 89: LearningRateScheduler setting learning rate to 0.00036317025996334415.\n",
            "Epoch 89/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0731 - dir_acc: 0.7487\n",
            "Epoch 89: dir_acc improved from 0.74411 to 0.74866, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 89: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.0731 - dir_acc: 0.7487 - val_loss: 0.1814 - val_dir_acc: 0.5423 - lr: 3.6317e-04\n",
            "\n",
            "Epoch 90: LearningRateScheduler setting learning rate to 0.00030791414801743875.\n",
            "Epoch 90/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0731 - dir_acc: 0.7453\n",
            "Epoch 90: dir_acc did not improve from 0.74866\n",
            "\n",
            "Epoch 90: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.0731 - dir_acc: 0.7453 - val_loss: 0.1831 - val_dir_acc: 0.5477 - lr: 3.0791e-04\n",
            "\n",
            "Epoch 91: LearningRateScheduler setting learning rate to 0.00025708267458346456.\n",
            "Epoch 91/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0721 - dir_acc: 0.7473\n",
            "Epoch 91: dir_acc did not improve from 0.74866\n",
            "\n",
            "Epoch 91: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.0721 - dir_acc: 0.7473 - val_loss: 0.1820 - val_dir_acc: 0.5463 - lr: 2.5708e-04\n",
            "\n",
            "Epoch 92: LearningRateScheduler setting learning rate to 0.00021077820748413085.\n",
            "Epoch 92/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0714 - dir_acc: 0.7516\n",
            "Epoch 92: dir_acc improved from 0.74866 to 0.75163, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 92: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.0714 - dir_acc: 0.7516 - val_loss: 0.1846 - val_dir_acc: 0.5436 - lr: 2.1078e-04\n",
            "\n",
            "Epoch 93: LearningRateScheduler setting learning rate to 0.00016909399775385568.\n",
            "Epoch 93/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0717 - dir_acc: 0.7506\n",
            "Epoch 93: dir_acc did not improve from 0.75163\n",
            "\n",
            "Epoch 93: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.0717 - dir_acc: 0.7506 - val_loss: 0.1869 - val_dir_acc: 0.5389 - lr: 1.6909e-04\n",
            "\n",
            "Epoch 94: LearningRateScheduler setting learning rate to 0.00013211399184359196.\n",
            "Epoch 94/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0712 - dir_acc: 0.7472\n",
            "Epoch 94: dir_acc did not improve from 0.75163\n",
            "\n",
            "Epoch 94: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.0712 - dir_acc: 0.7472 - val_loss: 0.1836 - val_dir_acc: 0.5328 - lr: 1.3211e-04\n",
            "\n",
            "Epoch 95: LearningRateScheduler setting learning rate to 9.991266256384617e-05.\n",
            "Epoch 95/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0710 - dir_acc: 0.7490\n",
            "Epoch 95: dir_acc did not improve from 0.75163\n",
            "\n",
            "Epoch 95: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.0710 - dir_acc: 0.7490 - val_loss: 0.1832 - val_dir_acc: 0.5402 - lr: 9.9913e-05\n",
            "\n",
            "Epoch 96: LearningRateScheduler setting learning rate to 7.255485910635008e-05.\n",
            "Epoch 96/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0704 - dir_acc: 0.7532\n",
            "Epoch 96: dir_acc improved from 0.75163 to 0.75322, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 96: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.0704 - dir_acc: 0.7532 - val_loss: 0.1819 - val_dir_acc: 0.5423 - lr: 7.2555e-05\n",
            "\n",
            "Epoch 97: LearningRateScheduler setting learning rate to 5.009567644641898e-05.\n",
            "Epoch 97/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0701 - dir_acc: 0.7536\n",
            "Epoch 97: dir_acc improved from 0.75322 to 0.75360, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 97: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.0701 - dir_acc: 0.7536 - val_loss: 0.1826 - val_dir_acc: 0.5436 - lr: 5.0096e-05\n",
            "\n",
            "Epoch 98: LearningRateScheduler setting learning rate to 3.258034438900293e-05.\n",
            "Epoch 98/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0699 - dir_acc: 0.7544\n",
            "Epoch 98: dir_acc improved from 0.75360 to 0.75445, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 98: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.0699 - dir_acc: 0.7544 - val_loss: 0.1833 - val_dir_acc: 0.5436 - lr: 3.2580e-05\n",
            "\n",
            "Epoch 99: LearningRateScheduler setting learning rate to 2.0044136481878526e-05.\n",
            "Epoch 99/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0702 - dir_acc: 0.7533\n",
            "Epoch 99: dir_acc did not improve from 0.75445\n",
            "\n",
            "Epoch 99: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.0702 - dir_acc: 0.7533 - val_loss: 0.1831 - val_dir_acc: 0.5436 - lr: 2.0044e-05\n",
            "\n",
            "Epoch 100: LearningRateScheduler setting learning rate to 1.25122989794201e-05.\n",
            "Epoch 100/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.0704 - dir_acc: 0.7511\n",
            "Epoch 100: dir_acc did not improve from 0.75445\n",
            "\n",
            "Epoch 100: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.0704 - dir_acc: 0.7511 - val_loss: 0.1832 - val_dir_acc: 0.5430 - lr: 1.2512e-05\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fa5f0546d70>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 100\n",
        "model.fit(train_sequences, train_labels,\n",
        "          validation_data=(validation_sequences, validation_labels),\n",
        "          epochs=EPOCHS,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          shuffle=True,\n",
        "          callbacks=[checkpoint_callback_train, checkpoint_callback_val, get_lr_callback(batch_size=BATCH_SIZE, epochs=EPOCHS)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFpSqzgXCE4K",
        "outputId": "357e5c28-3d46-4f8a-e899-9fd370ee71d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45/45 [==============================] - 1s 23ms/step - loss: 0.2595 - dir_acc: 0.5299\n",
            "directional accuracy=0.5299144983291626\n",
            "['loss', 'dir_acc']\n",
            "[0.2594867944717407, 0.5299144983291626]\n",
            "45/45 [==============================] - 1s 22ms/step\n",
            "R-squared: 0.7390832367578763\n"
          ]
        }
      ],
      "source": [
        "# Load Weights\n",
        "model.load_weights(\"transformer_val_model.keras\")\n",
        "\n",
        "# Make predictions\n",
        "evaluation = model.evaluate(test_sequences, test_labels)\n",
        "print(f\"directional accuracy={evaluation[1]}\")\n",
        "print(model.metrics_names)\n",
        "print(evaluation)\n",
        "\n",
        "# Calculate additional metrics as needed\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "predictions = model.predict(test_sequences)\n",
        "r2 = r2_score(test_labels[:, 1], predictions[:, 0])\n",
        "print(f\"R-squared: {r2}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.DataFrame({'actual':test_labels[:, 1], 'predicted':predictions[:, 0], 'error_ratio':(predictions[:, 0] - test_labels[:, 1])/test_labels[:, 1]})\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "dO6UBQsJyIWI",
        "outputId": "1e37dfeb-9eca-4464-81ff-550ee75eeba7"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        actual  predicted  error_ratio\n",
              "0    -0.050764   0.093572    -2.843285\n",
              "1    -0.089249   0.081537    -1.913594\n",
              "2    -0.078058   0.072196    -1.924895\n",
              "3    -0.113541   0.074804    -1.658833\n",
              "4    -0.099894   0.058235    -1.582968\n",
              "...        ...        ...          ...\n",
              "1416  1.116921   1.083238    -0.030156\n",
              "1417  1.124960   1.135816     0.009651\n",
              "1418  1.107381   1.102226    -0.004655\n",
              "1419  1.098162   1.102886     0.004301\n",
              "1420  1.082084   1.083122     0.000959\n",
              "\n",
              "[1421 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-311e127f-50e5-4c68-bd33-59609870a66b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>actual</th>\n",
              "      <th>predicted</th>\n",
              "      <th>error_ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.050764</td>\n",
              "      <td>0.093572</td>\n",
              "      <td>-2.843285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.089249</td>\n",
              "      <td>0.081537</td>\n",
              "      <td>-1.913594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.078058</td>\n",
              "      <td>0.072196</td>\n",
              "      <td>-1.924895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.113541</td>\n",
              "      <td>0.074804</td>\n",
              "      <td>-1.658833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.099894</td>\n",
              "      <td>0.058235</td>\n",
              "      <td>-1.582968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1416</th>\n",
              "      <td>1.116921</td>\n",
              "      <td>1.083238</td>\n",
              "      <td>-0.030156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1417</th>\n",
              "      <td>1.124960</td>\n",
              "      <td>1.135816</td>\n",
              "      <td>0.009651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1418</th>\n",
              "      <td>1.107381</td>\n",
              "      <td>1.102226</td>\n",
              "      <td>-0.004655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1419</th>\n",
              "      <td>1.098162</td>\n",
              "      <td>1.102886</td>\n",
              "      <td>0.004301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1420</th>\n",
              "      <td>1.082084</td>\n",
              "      <td>1.083122</td>\n",
              "      <td>0.000959</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1421 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-311e127f-50e5-4c68-bd33-59609870a66b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-311e127f-50e5-4c68-bd33-59609870a66b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-311e127f-50e5-4c68-bd33-59609870a66b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5686d8c1-71ad-43cb-b251-7646acb03e7c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5686d8c1-71ad-43cb-b251-7646acb03e7c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5686d8c1-71ad-43cb-b251-7646acb03e7c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results",
              "summary": "{\n  \"name\": \"results\",\n  \"rows\": 1421,\n  \"fields\": [\n    {\n      \"column\": \"actual\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6795175386659826,\n        \"min\": -0.8400514710884931,\n        \"max\": 2.057406849649502,\n        \"num_unique_values\": 905,\n        \"samples\": [\n          0.6998319574996132,\n          0.2059348001660586,\n          -0.412495039042843\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 1421,\n        \"samples\": [\n          0.23712365329265594,\n          -0.763157069683075,\n          0.09141699969768524\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"error_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 55.698189323107066,\n        \"min\": -143.64447838330713,\n        \"max\": 2084.9763141501116,\n        \"num_unique_values\": 1421,\n        \"samples\": [\n          6.005370621748892,\n          3.2485067590011245,\n          -0.8020013496139805\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "source": [
        "# @title actual vs predicted\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "results.plot(kind='scatter', x='actual', y='predicted', s=32, alpha=.8)\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "aTdM8GdQ0VEL",
        "outputId": "f3eb5884-2d67-4982-d01b-430ffefed0a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results['error_ratio'].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLNsy2LAyq8R",
        "outputId": "b3df5f61-14c5-40fd-ce00-d0db03f0e5eb"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0346508603648905"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}