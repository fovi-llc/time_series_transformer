{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fovi-com/MLTradingBot/blob/main/StockPricePredictionUsingTransformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The source of this notebook is (https://colab.research.google.com/drive/1j3AYSIxhiNJSCP692pKPbLk4_-kG4Pmh?usp=sharing) which accompanies this Medium article:  **Stock Price Prediction Using Transformers\n",
        "Introduction: Evolving Landscape of Stock Price Prediction** (https://medium.com/@Matthew_Frank/stock-price-prediction-using-transformers-2d84341ff213).\n",
        "\n",
        "Modifications by Jim White (https://www.linkedin.com/in/jamespaulwhite/)."
      ],
      "metadata": {
        "id": "XXZF8Z7ip54S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l9XA0tN3DEr",
        "outputId": "e5fc6e0c-2c0d-48bd-9d30-d87d493c6dd5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ziguS6k842Uo"
      },
      "outputs": [],
      "source": [
        "def calculate_bollinger_bands(data, window=10, num_of_std=2):\n",
        "    \"\"\"Calculate Bollinger Bands\"\"\"\n",
        "    rolling_mean = data.rolling(window=window).mean()\n",
        "    rolling_std = data.rolling(window=window).std()\n",
        "    upper_band = rolling_mean + (rolling_std * num_of_std)\n",
        "    lower_band = rolling_mean - (rolling_std * num_of_std)\n",
        "    return upper_band, lower_band\n",
        "\n",
        "def calculate_rsi(data, window=10):\n",
        "    \"\"\"Calculate Relative Strength Index\"\"\"\n",
        "    delta = data.diff()\n",
        "    gain = delta.clip(lower=0)\n",
        "    loss = -delta.clip(upper=0)\n",
        "    avg_gain = gain.rolling(window=window, min_periods=1).mean()\n",
        "    avg_loss = loss.rolling(window=window, min_periods=1).mean()\n",
        "    rs = avg_gain / avg_loss\n",
        "    rsi = 100 - (100 / (1 + rs))\n",
        "    return rsi\n",
        "\n",
        "def calculate_roc(data, periods=10):\n",
        "    \"\"\"Calculate Rate of Change.\"\"\"\n",
        "    roc = ((data - data.shift(periods)) / data.shift(periods)) * 100\n",
        "    return roc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AJOLtEZ04sYU"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, MultiHeadAttention, Add, GlobalAveragePooling1D\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RS9sQ0rD6RkC"
      },
      "outputs": [],
      "source": [
        "tickers = ['META', 'AAPL', 'MSFT', 'AMZN', 'GOOG']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YMAMF3D62zKD"
      },
      "outputs": [],
      "source": [
        "%load_ext dotenv\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.environ.get('POLYGON_API_KEY'):\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        try:\n",
        "            from google.colab import errors\n",
        "            os.environ['POLYGON_API_KEY'] = userdata.get('POLYGON_API_KEY').strip()\n",
        "        except Exception as ex:\n",
        "            print(ex)\n",
        "            pass\n",
        "        except errors.Error as err:\n",
        "            print(err)\n",
        "            pass\n",
        "    except ModuleNotFoundError:\n",
        "        pass\n",
        "\n",
        "    if not os.environ.get('POLYGON_API_KEY'):\n",
        "        import getpass\n",
        "        os.environ['POLYGON_API_KEY'] = getpass.getpass('Enter your Polygon API key: ').strip()\n",
        "\n",
        "    if not os.environ.get('POLYGON_API_KEY'):\n",
        "        raise ValueError('No Polygon API key provided')\n",
        "\n",
        "\n",
        "API_KEY = os.getenv('POLYGON_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "p4zRcn2p2zKD"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Function to get data from Polygon.io\n",
        "def get_polygon_data(ticker, api_key, multiplier='1', timespan='minute', from_date='2022-01-01', to_date='2022-12-31'):\n",
        "    url = f'https://api.polygon.io/v2/aggs/ticker/{ticker}/range/{multiplier}/{timespan}/{from_date}/{to_date}'\n",
        "    params = {\n",
        "        'adjusted': 'true',\n",
        "        'sort': 'asc',\n",
        "        'apiKey': api_key\n",
        "    }\n",
        "    response = requests.get(url, params=params)\n",
        "    data = response.json()\n",
        "    df = pd.DataFrame(data['results'])\n",
        "    df['timestamp'] = pd.to_datetime(df['t'], unit='ms')\n",
        "    df.set_index('timestamp', inplace=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "ticker_data_frames = []\n",
        "stats = {}\n",
        "\n",
        "\n",
        "from_date=\"2023-03-01\"\n",
        "to_date=\"2023-05-01\"\n",
        "data_folder = \"data\"\n",
        "\n",
        "for ticker in tickers:\n",
        "    saved_file_name = f'./{ticker}_{from_date}_{to_date}.csv'\n",
        "    saved_file_path = os.path.join(data_folder, saved_file_name)\n",
        "    # Download historical data for the ticker\n",
        "    if os.path.exists(saved_file_path):\n",
        "        data = pd.read_csv(saved_file_path)\n",
        "    else:\n",
        "        data = get_polygon_data(ticker, API_KEY, from_date=from_date, to_date=to_date)\n",
        "        #create a folder if it does not exist\n",
        "        if not os.path.exists(data_folder):\n",
        "            os.makedirs(data_folder)\n",
        "        data.to_csv(saved_file_path)\n",
        "\n",
        "\n",
        "    # Calculate the daily percentage change\n",
        "    close = data['c']\n",
        "    upper, lower = calculate_bollinger_bands(close, window=14, num_of_std=2)\n",
        "    width = upper - lower\n",
        "    rsi = calculate_rsi(close, window=14)\n",
        "    roc = calculate_roc(close, periods=14)\n",
        "    volume = data['v']\n",
        "    diff = close.diff(1)\n",
        "    percent_change_close = close.pct_change() * 100\n",
        "\n",
        "    # Create a DataFrame for the current ticker and append it to the list\n",
        "    ticker_df = pd.DataFrame({\n",
        "        ticker+'_close': close,\n",
        "        ticker+'_width': width,\n",
        "        ticker+'_rsi': rsi,\n",
        "        ticker+'_roc': roc,\n",
        "        ticker+'_volume': volume,\n",
        "        ticker+'_diff': diff,\n",
        "        ticker+'_percent_change_close': percent_change_close,\n",
        "    })\n",
        "\n",
        "    MEAN = ticker_df.mean()\n",
        "    STD = ticker_df.std()\n",
        "\n",
        "    # Keep track of mean and std\n",
        "    for column in MEAN.index:\n",
        "        stats[f\"{column}_mean\"] = MEAN[column]\n",
        "        stats[f\"{column}_std\"] = STD[column]\n",
        "\n",
        "    # Normalize the training features\n",
        "    ticker_df = (ticker_df - MEAN) / STD\n",
        "\n",
        "    ticker_data_frames.append(ticker_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f\"{len(ticker_data_frames)=}\""
      ],
      "metadata": {
        "id": "A5g75QMe4wzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ticker_data_frames[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "_ops0gFp6LoG",
        "outputId": "c0db8232-2829-471b-94fe-f88c78f46d90"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     AMZN_close  AMZN_width  AMZN_rsi  AMZN_roc  AMZN_volume  \\\n",
              "timestamp                                                                      \n",
              "2023-03-01 09:00:00    0.889262         NaN       NaN       NaN    -0.653276   \n",
              "2023-03-01 09:01:00    1.049595         NaN  3.160380       NaN    -0.664037   \n",
              "2023-03-01 09:02:00    0.965611         NaN  1.008604       NaN    -0.673217   \n",
              "2023-03-01 09:03:00    0.950341         NaN  0.766961       NaN    -0.671779   \n",
              "2023-03-01 09:04:00    1.080135         NaN  1.564767       NaN    -0.658064   \n",
              "...                         ...         ...       ...       ...          ...   \n",
              "2023-03-09 17:54:00    0.977063    0.830705 -1.038007 -1.119351     0.668118   \n",
              "2023-03-09 17:55:00    0.946524    0.553118 -1.749664 -1.706029     0.123838   \n",
              "2023-03-09 17:56:00    1.003786    0.214091 -1.173823 -1.177988     0.231965   \n",
              "2023-03-09 17:57:00    0.969428   -0.091438 -1.161148 -1.158595    -0.250340   \n",
              "2023-03-09 17:58:00    1.034325   -0.295717 -0.491253 -0.511508     0.368850   \n",
              "\n",
              "                     AMZN_diff  AMZN_percent_change_close  \n",
              "timestamp                                                  \n",
              "2023-03-01 09:00:00        NaN                        NaN  \n",
              "2023-03-01 09:01:00   2.972117                   2.937619  \n",
              "2023-03-01 09:02:00  -1.557643                  -1.536730  \n",
              "2023-03-01 09:03:00  -0.283648                  -0.280473  \n",
              "2023-03-01 09:04:00   2.405897                   2.375890  \n",
              "...                        ...                        ...  \n",
              "2023-03-09 17:54:00  -0.779091                  -0.769143  \n",
              "2023-03-09 17:55:00  -0.566758                  -0.559949  \n",
              "2023-03-09 17:56:00   1.061125                   1.047735  \n",
              "2023-03-09 17:57:00  -0.637536                  -0.629597  \n",
              "2023-03-09 17:58:00   1.202680                   1.187177  \n",
              "\n",
              "[5000 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c44e26af-423c-4662-ac9c-e7735d9a26cc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AMZN_close</th>\n",
              "      <th>AMZN_width</th>\n",
              "      <th>AMZN_rsi</th>\n",
              "      <th>AMZN_roc</th>\n",
              "      <th>AMZN_volume</th>\n",
              "      <th>AMZN_diff</th>\n",
              "      <th>AMZN_percent_change_close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-03-01 09:00:00</th>\n",
              "      <td>0.889262</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.653276</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-01 09:01:00</th>\n",
              "      <td>1.049595</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.160380</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.664037</td>\n",
              "      <td>2.972117</td>\n",
              "      <td>2.937619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-01 09:02:00</th>\n",
              "      <td>0.965611</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.008604</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.673217</td>\n",
              "      <td>-1.557643</td>\n",
              "      <td>-1.536730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-01 09:03:00</th>\n",
              "      <td>0.950341</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.766961</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.671779</td>\n",
              "      <td>-0.283648</td>\n",
              "      <td>-0.280473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-01 09:04:00</th>\n",
              "      <td>1.080135</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.564767</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.658064</td>\n",
              "      <td>2.405897</td>\n",
              "      <td>2.375890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-09 17:54:00</th>\n",
              "      <td>0.977063</td>\n",
              "      <td>0.830705</td>\n",
              "      <td>-1.038007</td>\n",
              "      <td>-1.119351</td>\n",
              "      <td>0.668118</td>\n",
              "      <td>-0.779091</td>\n",
              "      <td>-0.769143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-09 17:55:00</th>\n",
              "      <td>0.946524</td>\n",
              "      <td>0.553118</td>\n",
              "      <td>-1.749664</td>\n",
              "      <td>-1.706029</td>\n",
              "      <td>0.123838</td>\n",
              "      <td>-0.566758</td>\n",
              "      <td>-0.559949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-09 17:56:00</th>\n",
              "      <td>1.003786</td>\n",
              "      <td>0.214091</td>\n",
              "      <td>-1.173823</td>\n",
              "      <td>-1.177988</td>\n",
              "      <td>0.231965</td>\n",
              "      <td>1.061125</td>\n",
              "      <td>1.047735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-09 17:57:00</th>\n",
              "      <td>0.969428</td>\n",
              "      <td>-0.091438</td>\n",
              "      <td>-1.161148</td>\n",
              "      <td>-1.158595</td>\n",
              "      <td>-0.250340</td>\n",
              "      <td>-0.637536</td>\n",
              "      <td>-0.629597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-09 17:58:00</th>\n",
              "      <td>1.034325</td>\n",
              "      <td>-0.295717</td>\n",
              "      <td>-0.491253</td>\n",
              "      <td>-0.511508</td>\n",
              "      <td>0.368850</td>\n",
              "      <td>1.202680</td>\n",
              "      <td>1.187177</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5000 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c44e26af-423c-4662-ac9c-e7735d9a26cc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c44e26af-423c-4662-ac9c-e7735d9a26cc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c44e26af-423c-4662-ac9c-e7735d9a26cc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a17519d4-e1da-4ab3-b8bd-abbb430450f6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a17519d4-e1da-4ab3-b8bd-abbb430450f6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a17519d4-e1da-4ab3-b8bd-abbb430450f6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"ticker_data_frames[3]\",\n  \"rows\": 5000,\n  \"fields\": [\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2023-03-01 09:00:00\",\n        \"max\": \"2023-03-09 17:58:00\",\n        \"num_unique_values\": 5000,\n        \"samples\": [\n          \"2023-03-02 23:15:00\",\n          \"2023-03-06 14:47:00\",\n          \"2023-03-06 15:54:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AMZN_close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -2.324970229455644,\n        \"max\": 2.3169946833915014,\n        \"num_unique_values\": 1747,\n        \"samples\": [\n          1.274825880280211,\n          0.7327454039366013,\n          -1.5195608005896304\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AMZN_width\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9999999999999999,\n        \"min\": -1.227138383818406,\n        \"max\": 6.987135680510842,\n        \"num_unique_values\": 4864,\n        \"samples\": [\n          -1.0776654935616945,\n          0.9589356415068269,\n          -0.22676216534266777\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AMZN_rsi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -2.8843093695200195,\n        \"max\": 3.160380297388035,\n        \"num_unique_values\": 4486,\n        \"samples\": [\n          -0.4586691638062924,\n          0.10691498641997291,\n          -1.086883033660452\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AMZN_roc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9999999999999999,\n        \"min\": -6.6649134243983355,\n        \"max\": 5.259062518714536,\n        \"num_unique_values\": 4477,\n        \"samples\": [\n          -0.1998792178506255,\n          1.0565432320418617,\n          -0.32212745833543255\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AMZN_volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9999999999999999,\n        \"min\": -0.6845602364902718,\n        \"max\": 17.864344141398202,\n        \"num_unique_values\": 4338,\n        \"samples\": [\n          -0.6552747466660154,\n          -0.6746446769434763,\n          0.6250183489692188\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AMZN_diff\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9999999999999999,\n        \"min\": -8.975126546322137,\n        \"max\": 9.117021087299891,\n        \"num_unique_values\": 1249,\n        \"samples\": [\n          -0.7649351469787463,\n          -4.199060032290261,\n          -0.20579280167857975\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AMZN_percent_change_close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0,\n        \"min\": -8.919577521134485,\n        \"max\": 9.12126801304961,\n        \"num_unique_values\": 4038,\n        \"samples\": [\n          1.2765457541885468,\n          -0.14021936723577105,\n          0.2777147142403017\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "PoLOIDNN6jFB",
        "outputId": "fe84fdef-4984-4d8e-e9ae-a2f55053f813"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   META_close_mean  META_close_std  META_width_mean  META_width_std  \\\n",
              "0       181.888926        5.064389         0.884587         0.62428   \n",
              "\n",
              "   META_rsi_mean  META_rsi_std  META_roc_mean  META_roc_std  META_volume_mean  \\\n",
              "0      50.364641     17.046862       0.010671      0.353776         40953.215   \n",
              "\n",
              "   META_volume_std  ...  GOOG_rsi_mean  GOOG_rsi_std  GOOG_roc_mean  \\\n",
              "0     58312.124902  ...      49.670408     16.118251       0.002755   \n",
              "\n",
              "   GOOG_roc_std  GOOG_volume_mean  GOOG_volume_std  GOOG_diff_mean  \\\n",
              "0      0.277204        38381.1966     51424.301577        0.000192   \n",
              "\n",
              "   GOOG_diff_std  GOOG_percent_change_close_mean  \\\n",
              "0       0.076649                        0.000245   \n",
              "\n",
              "   GOOG_percent_change_close_std  \n",
              "0                       0.082652  \n",
              "\n",
              "[1 rows x 70 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6d1a74ab-5489-4592-9a65-5dbb4043cfd3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>META_close_mean</th>\n",
              "      <th>META_close_std</th>\n",
              "      <th>META_width_mean</th>\n",
              "      <th>META_width_std</th>\n",
              "      <th>META_rsi_mean</th>\n",
              "      <th>META_rsi_std</th>\n",
              "      <th>META_roc_mean</th>\n",
              "      <th>META_roc_std</th>\n",
              "      <th>META_volume_mean</th>\n",
              "      <th>META_volume_std</th>\n",
              "      <th>...</th>\n",
              "      <th>GOOG_rsi_mean</th>\n",
              "      <th>GOOG_rsi_std</th>\n",
              "      <th>GOOG_roc_mean</th>\n",
              "      <th>GOOG_roc_std</th>\n",
              "      <th>GOOG_volume_mean</th>\n",
              "      <th>GOOG_volume_std</th>\n",
              "      <th>GOOG_diff_mean</th>\n",
              "      <th>GOOG_diff_std</th>\n",
              "      <th>GOOG_percent_change_close_mean</th>\n",
              "      <th>GOOG_percent_change_close_std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>181.888926</td>\n",
              "      <td>5.064389</td>\n",
              "      <td>0.884587</td>\n",
              "      <td>0.62428</td>\n",
              "      <td>50.364641</td>\n",
              "      <td>17.046862</td>\n",
              "      <td>0.010671</td>\n",
              "      <td>0.353776</td>\n",
              "      <td>40953.215</td>\n",
              "      <td>58312.124902</td>\n",
              "      <td>...</td>\n",
              "      <td>49.670408</td>\n",
              "      <td>16.118251</td>\n",
              "      <td>0.002755</td>\n",
              "      <td>0.277204</td>\n",
              "      <td>38381.1966</td>\n",
              "      <td>51424.301577</td>\n",
              "      <td>0.000192</td>\n",
              "      <td>0.076649</td>\n",
              "      <td>0.000245</td>\n",
              "      <td>0.082652</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 70 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6d1a74ab-5489-4592-9a65-5dbb4043cfd3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6d1a74ab-5489-4592-9a65-5dbb4043cfd3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6d1a74ab-5489-4592-9a65-5dbb4043cfd3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "stats"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Convert stats from dict to df\n",
        "stats = pd.DataFrame([stats], index=[0])\n",
        "stats.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "qekxvEZk7woI",
        "outputId": "63ab08e4-33d9-4250-cabc-9fcd77f5548f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     META_close  META_width  META_rsi  META_roc  META_volume  \\\n",
              "timestamp                                                                      \n",
              "2023-03-01 10:55:00   -1.190455   -0.478390 -0.092067 -0.094443    -0.682452   \n",
              "2023-03-01 12:00:00   -1.261539   -0.657236 -0.830519 -0.801155    -0.609431   \n",
              "2023-03-01 12:01:00   -1.281285   -0.663242 -0.600536 -0.528861    -0.675918   \n",
              "2023-03-01 12:09:00   -1.285234   -0.438536 -0.233421 -0.223439    -0.674958   \n",
              "2023-03-01 13:00:00   -1.330649   -1.042758 -0.836138 -0.352565    -0.110838   \n",
              "\n",
              "                     META_diff  META_percent_change_close  AAPL_close  \\\n",
              "timestamp                                                               \n",
              "2023-03-01 10:55:00   0.873902                   0.903757   -0.539978   \n",
              "2023-03-01 12:00:00  -0.612235                  -0.634117   -0.579376   \n",
              "2023-03-01 12:01:00  -0.557193                  -0.577498   -0.576562   \n",
              "2023-03-01 12:09:00   0.158355                   0.163795   -0.573748   \n",
              "2023-03-01 13:00:00  -0.832403                  -0.863530   -0.607518   \n",
              "\n",
              "                     AAPL_width  AAPL_rsi  ...  AMZN_volume  AMZN_diff  \\\n",
              "timestamp                                  ...                           \n",
              "2023-03-01 10:55:00   -0.798726  1.183924  ...    -0.674820   0.282572   \n",
              "2023-03-01 12:00:00   -0.340900 -1.306480  ...    -0.619763  -1.840753   \n",
              "2023-03-01 12:01:00   -0.351032 -1.212886  ...    -0.637717  -0.566758   \n",
              "2023-03-01 12:09:00   -0.943849 -0.826813  ...    -0.656439  -0.708313   \n",
              "2023-03-01 13:00:00   -0.953176 -0.367317  ...    -0.263616  -0.991423   \n",
              "\n",
              "                     AMZN_percent_change_close  GOOG_close  GOOG_width  \\\n",
              "timestamp                                                                \n",
              "2023-03-01 10:55:00                   0.278420   -1.211776   -0.548373   \n",
              "2023-03-01 12:00:00                  -1.816162   -1.211776   -0.498211   \n",
              "2023-03-01 12:01:00                  -0.560215   -1.243933   -0.498211   \n",
              "2023-03-01 12:09:00                  -0.700189   -1.227854   -0.386283   \n",
              "2023-03-01 13:00:00                  -0.981247   -1.302887   -0.299948   \n",
              "\n",
              "                     GOOG_rsi  GOOG_roc  GOOG_volume  GOOG_diff  \\\n",
              "timestamp                                                         \n",
              "2023-03-01 10:55:00  0.703956  0.506604    -0.740160   0.780287   \n",
              "2023-03-01 12:00:00 -0.065720 -0.089276    -0.609579  -1.046229   \n",
              "2023-03-01 12:01:00  0.020448 -0.009939    -0.725731  -0.785298   \n",
              "2023-03-01 12:09:00 -0.379819 -0.327183    -0.726256   0.127960   \n",
              "2023-03-01 13:00:00 -1.819765 -1.395900    -0.301729  -0.263436   \n",
              "\n",
              "                     GOOG_percent_change_close  \n",
              "timestamp                                       \n",
              "2023-03-01 10:55:00                   0.795998  \n",
              "2023-03-01 12:00:00                  -1.066610  \n",
              "2023-03-01 12:01:00                  -0.801400  \n",
              "2023-03-01 12:09:00                   0.130166  \n",
              "2023-03-01 13:00:00                  -0.269550  \n",
              "\n",
              "[5 rows x 35 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1889e7fd-a798-4da0-b14c-314afa317d20\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>META_close</th>\n",
              "      <th>META_width</th>\n",
              "      <th>META_rsi</th>\n",
              "      <th>META_roc</th>\n",
              "      <th>META_volume</th>\n",
              "      <th>META_diff</th>\n",
              "      <th>META_percent_change_close</th>\n",
              "      <th>AAPL_close</th>\n",
              "      <th>AAPL_width</th>\n",
              "      <th>AAPL_rsi</th>\n",
              "      <th>...</th>\n",
              "      <th>AMZN_volume</th>\n",
              "      <th>AMZN_diff</th>\n",
              "      <th>AMZN_percent_change_close</th>\n",
              "      <th>GOOG_close</th>\n",
              "      <th>GOOG_width</th>\n",
              "      <th>GOOG_rsi</th>\n",
              "      <th>GOOG_roc</th>\n",
              "      <th>GOOG_volume</th>\n",
              "      <th>GOOG_diff</th>\n",
              "      <th>GOOG_percent_change_close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-03-01 10:55:00</th>\n",
              "      <td>-1.190455</td>\n",
              "      <td>-0.478390</td>\n",
              "      <td>-0.092067</td>\n",
              "      <td>-0.094443</td>\n",
              "      <td>-0.682452</td>\n",
              "      <td>0.873902</td>\n",
              "      <td>0.903757</td>\n",
              "      <td>-0.539978</td>\n",
              "      <td>-0.798726</td>\n",
              "      <td>1.183924</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.674820</td>\n",
              "      <td>0.282572</td>\n",
              "      <td>0.278420</td>\n",
              "      <td>-1.211776</td>\n",
              "      <td>-0.548373</td>\n",
              "      <td>0.703956</td>\n",
              "      <td>0.506604</td>\n",
              "      <td>-0.740160</td>\n",
              "      <td>0.780287</td>\n",
              "      <td>0.795998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-01 12:00:00</th>\n",
              "      <td>-1.261539</td>\n",
              "      <td>-0.657236</td>\n",
              "      <td>-0.830519</td>\n",
              "      <td>-0.801155</td>\n",
              "      <td>-0.609431</td>\n",
              "      <td>-0.612235</td>\n",
              "      <td>-0.634117</td>\n",
              "      <td>-0.579376</td>\n",
              "      <td>-0.340900</td>\n",
              "      <td>-1.306480</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.619763</td>\n",
              "      <td>-1.840753</td>\n",
              "      <td>-1.816162</td>\n",
              "      <td>-1.211776</td>\n",
              "      <td>-0.498211</td>\n",
              "      <td>-0.065720</td>\n",
              "      <td>-0.089276</td>\n",
              "      <td>-0.609579</td>\n",
              "      <td>-1.046229</td>\n",
              "      <td>-1.066610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-01 12:01:00</th>\n",
              "      <td>-1.281285</td>\n",
              "      <td>-0.663242</td>\n",
              "      <td>-0.600536</td>\n",
              "      <td>-0.528861</td>\n",
              "      <td>-0.675918</td>\n",
              "      <td>-0.557193</td>\n",
              "      <td>-0.577498</td>\n",
              "      <td>-0.576562</td>\n",
              "      <td>-0.351032</td>\n",
              "      <td>-1.212886</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.637717</td>\n",
              "      <td>-0.566758</td>\n",
              "      <td>-0.560215</td>\n",
              "      <td>-1.243933</td>\n",
              "      <td>-0.498211</td>\n",
              "      <td>0.020448</td>\n",
              "      <td>-0.009939</td>\n",
              "      <td>-0.725731</td>\n",
              "      <td>-0.785298</td>\n",
              "      <td>-0.801400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-01 12:09:00</th>\n",
              "      <td>-1.285234</td>\n",
              "      <td>-0.438536</td>\n",
              "      <td>-0.233421</td>\n",
              "      <td>-0.223439</td>\n",
              "      <td>-0.674958</td>\n",
              "      <td>0.158355</td>\n",
              "      <td>0.163795</td>\n",
              "      <td>-0.573748</td>\n",
              "      <td>-0.943849</td>\n",
              "      <td>-0.826813</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.656439</td>\n",
              "      <td>-0.708313</td>\n",
              "      <td>-0.700189</td>\n",
              "      <td>-1.227854</td>\n",
              "      <td>-0.386283</td>\n",
              "      <td>-0.379819</td>\n",
              "      <td>-0.327183</td>\n",
              "      <td>-0.726256</td>\n",
              "      <td>0.127960</td>\n",
              "      <td>0.130166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-03-01 13:00:00</th>\n",
              "      <td>-1.330649</td>\n",
              "      <td>-1.042758</td>\n",
              "      <td>-0.836138</td>\n",
              "      <td>-0.352565</td>\n",
              "      <td>-0.110838</td>\n",
              "      <td>-0.832403</td>\n",
              "      <td>-0.863530</td>\n",
              "      <td>-0.607518</td>\n",
              "      <td>-0.953176</td>\n",
              "      <td>-0.367317</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.263616</td>\n",
              "      <td>-0.991423</td>\n",
              "      <td>-0.981247</td>\n",
              "      <td>-1.302887</td>\n",
              "      <td>-0.299948</td>\n",
              "      <td>-1.819765</td>\n",
              "      <td>-1.395900</td>\n",
              "      <td>-0.301729</td>\n",
              "      <td>-0.263436</td>\n",
              "      <td>-0.269550</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 35 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1889e7fd-a798-4da0-b14c-314afa317d20')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1889e7fd-a798-4da0-b14c-314afa317d20 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1889e7fd-a798-4da0-b14c-314afa317d20');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-10c62d4c-608c-4fcf-ba3e-d75afe171859\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-10c62d4c-608c-4fcf-ba3e-d75afe171859')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-10c62d4c-608c-4fcf-ba3e-d75afe171859 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Concatenate all ticker DataFrames\n",
        "df = pd.concat(ticker_data_frames, axis=1)\n",
        "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "l_DDzDQp8Hju"
      },
      "outputs": [],
      "source": [
        "# Shift the df data to create labels\n",
        "labels = df.shift(-1)\n",
        "# Drop the last row in both percent_change_data and labels as it won't have a corresponding label\n",
        "df = df.iloc[:-1]\n",
        "labels = labels.iloc[:-1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "k0Jdnzly9FQ3"
      },
      "outputs": [],
      "source": [
        "# Sequence len = 24 means that we have 2 hours of 5 min data\n",
        "SEQUENCE_LEN = 24\n",
        "\n",
        "# Function to create X-day sequences for each ticker\n",
        "def create_sequences(data, labels, mean, std, sequence_length=SEQUENCE_LEN):\n",
        "    sequences = []\n",
        "    lab = []\n",
        "    data_size = len(data)\n",
        "\n",
        "    # + 12 because we want to predict the next hour\n",
        "    for i in range(data_size - (sequence_length + 13)):\n",
        "      if i == 0:\n",
        "        continue\n",
        "\n",
        "      sequences.append(data[i:i + sequence_length])\n",
        "      lab.append([labels[i], labels[i + 11], mean[0], std[0]])\n",
        "\n",
        "    return np.array(sequences), np.array(lab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "y4Mh2yj79Ud9"
      },
      "outputs": [],
      "source": [
        "sequences_dict = {}\n",
        "sequence_labels = {}\n",
        "for ticker in tickers:\n",
        "\n",
        "    # Extract close and volume data for the ticker\n",
        "    close = df[ticker+'_close'].values\n",
        "    width = df[ticker+'_width'].values\n",
        "    rsi = df[ticker+'_rsi'].values\n",
        "    roc = df[ticker+'_roc'].values\n",
        "    volume = df[ticker+'_volume'].values\n",
        "    diff = df[ticker+'_diff'].values\n",
        "    pct_change = df[ticker+'_percent_change_close'].values\n",
        "\n",
        "    # Combine close and volume data\n",
        "    ticker_data = np.column_stack((close,\n",
        "                                   width,\n",
        "                                   rsi,\n",
        "                                   roc,\n",
        "                                   volume,\n",
        "                                   diff,\n",
        "                                   pct_change))\n",
        "\n",
        "    # Generate sequences\n",
        "    attribute = ticker+\"_close\"\n",
        "    ticker_sequences, lab = create_sequences(ticker_data,\n",
        "                                             labels[attribute].values[SEQUENCE_LEN-1:],\n",
        "                                             stats[attribute+\"_mean\"].values,\n",
        "                                             stats[attribute+\"_std\"].values)\n",
        "\n",
        "    sequences_dict[ticker] = ticker_sequences\n",
        "    sequence_labels[ticker] = lab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "yRQ0zowW2zKF",
        "outputId": "51c87922-28df-48d7-fa96-109c8c8a687f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3007, 24, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "sequences_dict['META'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "nKbFo1mH2zKG",
        "outputId": "af7a9830-1811-4dbc-a7b9-7a81609c9a36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.4491237 , -0.7667115 ,  0.46745801,  0.29408539, -0.68041106,\n",
              "        0.26843901,  0.27930452])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "sequences_dict['META'][2][-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "5mZZJmuS2zKG",
        "outputId": "ae9abf2b-0156-4298-b5b0-83f3e585aba5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3007, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "sequence_labels['META'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "XIl_sq4O2zKG",
        "outputId": "fadbcc12-f9cc-4f72-b368-75a1d9866efa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ -1.43925084,  -1.53008114, 181.8889262 ,   5.06438907])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "sequence_labels['META'][2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "-oXY-sXP-fnZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a261aa8-52ac-43ab-fb31-3442f5a564b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_sequences.shape=(12025, 24, 7)\n",
            "train_labels.shape=(12025, 4)\n",
            "other_sequences.shape=(2890, 24, 7)\n",
            "other_labels.shape=(2890, 4)\n"
          ]
        }
      ],
      "source": [
        "# Combine data and labels from all tickers\n",
        "\n",
        "TRAIN_FRACTION = 0.8\n",
        "\n",
        "train_sequences = []\n",
        "train_labels = []\n",
        "other_sequences = []\n",
        "other_labels = []\n",
        "\n",
        "def extend_sequences(ticker):\n",
        "  ticker_sequence = sequences_dict[ticker]\n",
        "  ticker_labels = sequence_labels[ticker]\n",
        "  seq_len = len(ticker_sequence)\n",
        "  assert seq_len == len(ticker_labels)\n",
        "  train_len = int(seq_len * TRAIN_FRACTION)\n",
        "  train_sequences.extend(ticker_sequence[:train_len])\n",
        "  train_labels.extend(ticker_labels[:train_len])\n",
        "  other_sequences.extend(ticker_sequence[train_len + SEQUENCE_LEN:])\n",
        "  other_labels.extend(ticker_labels[train_len + SEQUENCE_LEN:])\n",
        "\n",
        "\n",
        "for ticker in tickers:\n",
        "    extend_sequences(ticker)\n",
        "\n",
        "# Convert to numpy arrays\n",
        "train_sequences = np.array(train_sequences)\n",
        "train_labels = np.array(train_labels)\n",
        "other_sequences = np.array(other_sequences)\n",
        "other_labels = np.array(other_labels)\n",
        "\n",
        "print(f\"{train_sequences.shape=}\")\n",
        "print(f\"{train_labels.shape=}\")\n",
        "print(f\"{other_sequences.shape=}\")\n",
        "print(f\"{other_labels.shape=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "8QY42PaV-kPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f5c5c69-ba93-4e51-be2c-a1ad2f26ec54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation_sequences.shape=(1421, 24, 7)\n",
            "validation_labels.shape=(1421, 4)\n",
            "test_sequences.shape=(1421, 24, 7)\n",
            "test_labels.shape=(1421, 4)\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "# Randomize the order of the training data\n",
        "shuffled_indices = np.random.permutation(len(train_sequences))\n",
        "train_sequences = train_sequences[shuffled_indices]\n",
        "train_labels = train_labels[shuffled_indices]\n",
        "\n",
        "# Validation/Test split is 50/50\n",
        "# Need to leave gaps between the train, val, and test samples so they don't overlap in time.\n",
        "val_size = int(len(other_sequences) * 0.5)\n",
        "\n",
        "validation_sequences = other_sequences[SEQUENCE_LEN:val_size]\n",
        "validation_labels = other_labels[SEQUENCE_LEN:val_size]\n",
        "\n",
        "test_sequences = other_sequences[val_size + SEQUENCE_LEN:]\n",
        "test_labels = other_labels[val_size + SEQUENCE_LEN:]\n",
        "\n",
        "print(f\"{validation_sequences.shape=}\")\n",
        "print(f\"{validation_labels.shape=}\")\n",
        "print(f\"{test_sequences.shape=}\")\n",
        "print(f\"{test_labels.shape=}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBKt-Fhj-p3w",
        "outputId": "fec35474-8f5a-4009-87db-0b566e5e08f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)        [(None, 24, 7)]              0         []                            \n",
            "                                                                                                  \n",
            " layer_normalization_100 (L  (None, 24, 7)                14        ['input_5[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_48 (M  (None, 24, 7)                126983    ['layer_normalization_100[0][0\n",
            " ultiHeadAttention)                                                 ]',                           \n",
            "                                                                     'layer_normalization_100[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_96 (Add)                (None, 24, 7)                0         ['multi_head_attention_48[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'input_5[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_101 (L  (None, 24, 7)                14        ['add_96[0][0]']              \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_100 (Dense)           (None, 24, 1024)             8192      ['layer_normalization_101[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_48 (Dropout)        (None, 24, 1024)             0         ['dense_100[0][0]']           \n",
            "                                                                                                  \n",
            " dense_101 (Dense)           (None, 24, 7)                7175      ['dropout_48[0][0]']          \n",
            "                                                                                                  \n",
            " add_97 (Add)                (None, 24, 7)                0         ['dense_101[0][0]',           \n",
            "                                                                     'add_96[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_102 (L  (None, 24, 7)                14        ['add_97[0][0]']              \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_49 (M  (None, 24, 7)                126983    ['layer_normalization_102[0][0\n",
            " ultiHeadAttention)                                                 ]',                           \n",
            "                                                                     'layer_normalization_102[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_98 (Add)                (None, 24, 7)                0         ['multi_head_attention_49[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_97[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_103 (L  (None, 24, 7)                14        ['add_98[0][0]']              \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_102 (Dense)           (None, 24, 1024)             8192      ['layer_normalization_103[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_49 (Dropout)        (None, 24, 1024)             0         ['dense_102[0][0]']           \n",
            "                                                                                                  \n",
            " dense_103 (Dense)           (None, 24, 7)                7175      ['dropout_49[0][0]']          \n",
            "                                                                                                  \n",
            " add_99 (Add)                (None, 24, 7)                0         ['dense_103[0][0]',           \n",
            "                                                                     'add_98[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_104 (L  (None, 24, 7)                14        ['add_99[0][0]']              \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_50 (M  (None, 24, 7)                126983    ['layer_normalization_104[0][0\n",
            " ultiHeadAttention)                                                 ]',                           \n",
            "                                                                     'layer_normalization_104[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_100 (Add)               (None, 24, 7)                0         ['multi_head_attention_50[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_99[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_105 (L  (None, 24, 7)                14        ['add_100[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_104 (Dense)           (None, 24, 1024)             8192      ['layer_normalization_105[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_50 (Dropout)        (None, 24, 1024)             0         ['dense_104[0][0]']           \n",
            "                                                                                                  \n",
            " dense_105 (Dense)           (None, 24, 7)                7175      ['dropout_50[0][0]']          \n",
            "                                                                                                  \n",
            " add_101 (Add)               (None, 24, 7)                0         ['dense_105[0][0]',           \n",
            "                                                                     'add_100[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_106 (L  (None, 24, 7)                14        ['add_101[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_51 (M  (None, 24, 7)                126983    ['layer_normalization_106[0][0\n",
            " ultiHeadAttention)                                                 ]',                           \n",
            "                                                                     'layer_normalization_106[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_102 (Add)               (None, 24, 7)                0         ['multi_head_attention_51[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_101[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_107 (L  (None, 24, 7)                14        ['add_102[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_106 (Dense)           (None, 24, 1024)             8192      ['layer_normalization_107[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_51 (Dropout)        (None, 24, 1024)             0         ['dense_106[0][0]']           \n",
            "                                                                                                  \n",
            " dense_107 (Dense)           (None, 24, 7)                7175      ['dropout_51[0][0]']          \n",
            "                                                                                                  \n",
            " add_103 (Add)               (None, 24, 7)                0         ['dense_107[0][0]',           \n",
            "                                                                     'add_102[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_108 (L  (None, 24, 7)                14        ['add_103[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_52 (M  (None, 24, 7)                126983    ['layer_normalization_108[0][0\n",
            " ultiHeadAttention)                                                 ]',                           \n",
            "                                                                     'layer_normalization_108[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_104 (Add)               (None, 24, 7)                0         ['multi_head_attention_52[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_103[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_109 (L  (None, 24, 7)                14        ['add_104[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_108 (Dense)           (None, 24, 1024)             8192      ['layer_normalization_109[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_52 (Dropout)        (None, 24, 1024)             0         ['dense_108[0][0]']           \n",
            "                                                                                                  \n",
            " dense_109 (Dense)           (None, 24, 7)                7175      ['dropout_52[0][0]']          \n",
            "                                                                                                  \n",
            " add_105 (Add)               (None, 24, 7)                0         ['dense_109[0][0]',           \n",
            "                                                                     'add_104[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_110 (L  (None, 24, 7)                14        ['add_105[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_53 (M  (None, 24, 7)                126983    ['layer_normalization_110[0][0\n",
            " ultiHeadAttention)                                                 ]',                           \n",
            "                                                                     'layer_normalization_110[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_106 (Add)               (None, 24, 7)                0         ['multi_head_attention_53[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_105[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_111 (L  (None, 24, 7)                14        ['add_106[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_110 (Dense)           (None, 24, 1024)             8192      ['layer_normalization_111[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_53 (Dropout)        (None, 24, 1024)             0         ['dense_110[0][0]']           \n",
            "                                                                                                  \n",
            " dense_111 (Dense)           (None, 24, 7)                7175      ['dropout_53[0][0]']          \n",
            "                                                                                                  \n",
            " add_107 (Add)               (None, 24, 7)                0         ['dense_111[0][0]',           \n",
            "                                                                     'add_106[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_112 (L  (None, 24, 7)                14        ['add_107[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_54 (M  (None, 24, 7)                126983    ['layer_normalization_112[0][0\n",
            " ultiHeadAttention)                                                 ]',                           \n",
            "                                                                     'layer_normalization_112[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_108 (Add)               (None, 24, 7)                0         ['multi_head_attention_54[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_107[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_113 (L  (None, 24, 7)                14        ['add_108[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_112 (Dense)           (None, 24, 1024)             8192      ['layer_normalization_113[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_54 (Dropout)        (None, 24, 1024)             0         ['dense_112[0][0]']           \n",
            "                                                                                                  \n",
            " dense_113 (Dense)           (None, 24, 7)                7175      ['dropout_54[0][0]']          \n",
            "                                                                                                  \n",
            " add_109 (Add)               (None, 24, 7)                0         ['dense_113[0][0]',           \n",
            "                                                                     'add_108[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_114 (L  (None, 24, 7)                14        ['add_109[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_55 (M  (None, 24, 7)                126983    ['layer_normalization_114[0][0\n",
            " ultiHeadAttention)                                                 ]',                           \n",
            "                                                                     'layer_normalization_114[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_110 (Add)               (None, 24, 7)                0         ['multi_head_attention_55[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_109[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_115 (L  (None, 24, 7)                14        ['add_110[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_114 (Dense)           (None, 24, 1024)             8192      ['layer_normalization_115[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_55 (Dropout)        (None, 24, 1024)             0         ['dense_114[0][0]']           \n",
            "                                                                                                  \n",
            " dense_115 (Dense)           (None, 24, 7)                7175      ['dropout_55[0][0]']          \n",
            "                                                                                                  \n",
            " add_111 (Add)               (None, 24, 7)                0         ['dense_115[0][0]',           \n",
            "                                                                     'add_110[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_116 (L  (None, 24, 7)                14        ['add_111[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_56 (M  (None, 24, 7)                126983    ['layer_normalization_116[0][0\n",
            " ultiHeadAttention)                                                 ]',                           \n",
            "                                                                     'layer_normalization_116[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_112 (Add)               (None, 24, 7)                0         ['multi_head_attention_56[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_111[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_117 (L  (None, 24, 7)                14        ['add_112[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_116 (Dense)           (None, 24, 1024)             8192      ['layer_normalization_117[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_56 (Dropout)        (None, 24, 1024)             0         ['dense_116[0][0]']           \n",
            "                                                                                                  \n",
            " dense_117 (Dense)           (None, 24, 7)                7175      ['dropout_56[0][0]']          \n",
            "                                                                                                  \n",
            " add_113 (Add)               (None, 24, 7)                0         ['dense_117[0][0]',           \n",
            "                                                                     'add_112[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_118 (L  (None, 24, 7)                14        ['add_113[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_57 (M  (None, 24, 7)                126983    ['layer_normalization_118[0][0\n",
            " ultiHeadAttention)                                                 ]',                           \n",
            "                                                                     'layer_normalization_118[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_114 (Add)               (None, 24, 7)                0         ['multi_head_attention_57[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_113[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_119 (L  (None, 24, 7)                14        ['add_114[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_118 (Dense)           (None, 24, 1024)             8192      ['layer_normalization_119[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_57 (Dropout)        (None, 24, 1024)             0         ['dense_118[0][0]']           \n",
            "                                                                                                  \n",
            " dense_119 (Dense)           (None, 24, 7)                7175      ['dropout_57[0][0]']          \n",
            "                                                                                                  \n",
            " add_115 (Add)               (None, 24, 7)                0         ['dense_119[0][0]',           \n",
            "                                                                     'add_114[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_120 (L  (None, 24, 7)                14        ['add_115[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_58 (M  (None, 24, 7)                126983    ['layer_normalization_120[0][0\n",
            " ultiHeadAttention)                                                 ]',                           \n",
            "                                                                     'layer_normalization_120[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_116 (Add)               (None, 24, 7)                0         ['multi_head_attention_58[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_115[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_121 (L  (None, 24, 7)                14        ['add_116[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_120 (Dense)           (None, 24, 1024)             8192      ['layer_normalization_121[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_58 (Dropout)        (None, 24, 1024)             0         ['dense_120[0][0]']           \n",
            "                                                                                                  \n",
            " dense_121 (Dense)           (None, 24, 7)                7175      ['dropout_58[0][0]']          \n",
            "                                                                                                  \n",
            " add_117 (Add)               (None, 24, 7)                0         ['dense_121[0][0]',           \n",
            "                                                                     'add_116[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_122 (L  (None, 24, 7)                14        ['add_117[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " multi_head_attention_59 (M  (None, 24, 7)                126983    ['layer_normalization_122[0][0\n",
            " ultiHeadAttention)                                                 ]',                           \n",
            "                                                                     'layer_normalization_122[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " add_118 (Add)               (None, 24, 7)                0         ['multi_head_attention_59[0][0\n",
            "                                                                    ]',                           \n",
            "                                                                     'add_117[0][0]']             \n",
            "                                                                                                  \n",
            " layer_normalization_123 (L  (None, 24, 7)                14        ['add_118[0][0]']             \n",
            " ayerNormalization)                                                                               \n",
            "                                                                                                  \n",
            " dense_122 (Dense)           (None, 24, 1024)             8192      ['layer_normalization_123[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            " dropout_59 (Dropout)        (None, 24, 1024)             0         ['dense_122[0][0]']           \n",
            "                                                                                                  \n",
            " dense_123 (Dense)           (None, 24, 7)                7175      ['dropout_59[0][0]']          \n",
            "                                                                                                  \n",
            " add_119 (Add)               (None, 24, 7)                0         ['dense_123[0][0]',           \n",
            "                                                                     'add_118[0][0]']             \n",
            "                                                                                                  \n",
            " global_average_pooling1d_4  (None, 7)                    0         ['add_119[0][0]']             \n",
            "  (GlobalAveragePooling1D)                                                                        \n",
            "                                                                                                  \n",
            " layer_normalization_124 (L  (None, 7)                    14        ['global_average_pooling1d_4[0\n",
            " ayerNormalization)                                                 ][0]']                        \n",
            "                                                                                                  \n",
            " dense_124 (Dense)           (None, 1)                    8         ['layer_normalization_124[0][0\n",
            "                                                                    ]']                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1708558 (6.52 MB)\n",
            "Trainable params: 1708558 (6.52 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Attention and Normalization\n",
        "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(x, x)\n",
        "    x = Add()([x, inputs])\n",
        "\n",
        "    # Feed Forward Part\n",
        "    y = LayerNormalization(epsilon=1e-6)(x)\n",
        "    y = Dense(ff_dim, activation=\"relu\")(y)\n",
        "    y = Dropout(dropout)(y)\n",
        "    y = Dense(inputs.shape[-1])(y)\n",
        "    return Add()([y, x])\n",
        "\n",
        "def build_transformer_model(input_shape, head_size, num_heads, ff_dim, num_layers, dropout=0):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = inputs\n",
        "\n",
        "    # Create multiple layers of the Transformer block\n",
        "    for _ in range(num_layers):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    # Final part of the model\n",
        "    x = GlobalAveragePooling1D()(x)\n",
        "    x = LayerNormalization(epsilon=1e-6)(x)\n",
        "    outputs = Dense(1, activation=\"linear\")(x)\n",
        "\n",
        "    # Compile model\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Model parameters\n",
        "input_shape = train_sequences.shape[1:]\n",
        "head_size = 256\n",
        "num_heads = 16\n",
        "ff_dim = 1024\n",
        "num_layers = 12\n",
        "dropout = 0.20\n",
        "\n",
        "# Build the model\n",
        "model = build_transformer_model(input_shape, head_size, num_heads, ff_dim, num_layers, dropout)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "bWMOzku9-vpv"
      },
      "outputs": [],
      "source": [
        "def custom_mae_loss(y_true, y_pred):\n",
        "    y_true_next = tf.cast(y_true[:, 1], tf.float64)\n",
        "    y_pred_next = tf.cast(y_pred[:, 0], tf.float64)\n",
        "    abs_error = tf.abs(y_true_next - y_pred_next)\n",
        "\n",
        "    return tf.reduce_mean(abs_error)\n",
        "\n",
        "def dir_acc(y_true, y_pred):\n",
        "    mean, std = tf.cast(y_true[:, 2], tf.float64), tf.cast(y_true[:, 3], tf.float64)\n",
        "\n",
        "    y_true_prev = (tf.cast(y_true[:, 0], tf.float64) * std) + mean\n",
        "    y_true_next = (tf.cast(y_true[:, 1], tf.float64) * std) + mean\n",
        "    y_pred_next = (tf.cast(y_pred[:, 0], tf.float64) * std) + mean\n",
        "\n",
        "    true_change = y_true_next - y_true_prev\n",
        "    pred_change = y_pred_next - y_true_prev\n",
        "\n",
        "    correct_direction = tf.equal(tf.sign(true_change), tf.sign(pred_change))\n",
        "\n",
        "    return tf.reduce_mean(tf.cast(correct_direction, tf.float64))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "CQ20qXHdABEa"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model.compile(optimizer=optimizer, loss=custom_mae_loss, metrics=[dir_acc])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "1kVujFs0BQu8"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Define a callback to save the best model\n",
        "checkpoint_callback_train = ModelCheckpoint(\n",
        "    \"transformer_train_model.keras\",  # Filepath to save the best model\n",
        "    monitor=\"dir_acc\",  #\"loss\",  # Metric to monitor\n",
        "    save_best_only=True,  # Save only the best model\n",
        "    mode=\"max\",  # Minimize the monitored metric\n",
        "    verbose=1,  # Display progress\n",
        ")\n",
        "\n",
        "# Define a callback to save the best model\n",
        "checkpoint_callback_val = ModelCheckpoint(\n",
        "    \"transformer_val_model.keras\",  # Filepath to save the best model\n",
        "    monitor=\"val_dir_acc\", #\"val_loss\",  # Metric to monitor\n",
        "    save_best_only=True,  # Save only the best model\n",
        "    mode=\"max\",  # Minimize the monitored metric\n",
        "    verbose=1,  # Display progress\n",
        ")\n",
        "\n",
        "def get_lr_callback(batch_size=16, mode='cos', epochs=500, plot=False):\n",
        "    lr_start, lr_max, lr_min = 0.0001, 0.005, 0.00001  # Adjust learning rate boundaries\n",
        "    lr_ramp_ep = int(0.30 * epochs)  # 30% of epochs for warm-up\n",
        "    lr_sus_ep = max(0, int(0.10 * epochs) - lr_ramp_ep)  # Optional sustain phase, adjust as needed\n",
        "\n",
        "    def lrfn(epoch):\n",
        "        if epoch < lr_ramp_ep:  # Warm-up phase\n",
        "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
        "        elif epoch < lr_ramp_ep + lr_sus_ep:  # Sustain phase at max learning rate\n",
        "            lr = lr_max\n",
        "        elif mode == 'cos':\n",
        "            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep, epoch - lr_ramp_ep - lr_sus_ep\n",
        "            phase = math.pi * decay_epoch_index / decay_total_epochs\n",
        "            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n",
        "        else:\n",
        "            lr = lr_min  # Default to minimum learning rate if mode is not recognized\n",
        "\n",
        "        return lr\n",
        "\n",
        "    if plot:  # Plot learning rate curve if plot is True\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Learning Rate')\n",
        "        plt.title('Learning Rate Scheduler')\n",
        "        plt.show()\n",
        "\n",
        "    return tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wwlX1n52zKI"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Mv3B5gvBeR-",
        "outputId": "07d3f336-c2d4-4f85-f1f9-1f032e7720be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0001.\n",
            "Epoch 1/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.2304 - dir_acc: 0.5264\n",
            "Epoch 1: dir_acc improved from -inf to 0.52636, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 1: val_dir_acc improved from -inf to 0.58628, saving model to transformer_val_model.keras\n",
            "188/188 [==============================] - 54s 110ms/step - loss: 0.2304 - dir_acc: 0.5264 - val_loss: 0.1908 - val_dir_acc: 0.5863 - lr: 1.0000e-04\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.00026333333333333336.\n",
            "Epoch 2/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1990 - dir_acc: 0.5349\n",
            "Epoch 2: dir_acc improved from 0.52636 to 0.53492, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 2: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.1990 - dir_acc: 0.5349 - val_loss: 0.1582 - val_dir_acc: 0.5554 - lr: 2.6333e-04\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.00042666666666666667.\n",
            "Epoch 3/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1948 - dir_acc: 0.5388\n",
            "Epoch 3: dir_acc improved from 0.53492 to 0.53877, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 3: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.1948 - dir_acc: 0.5388 - val_loss: 0.1864 - val_dir_acc: 0.5666 - lr: 4.2667e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.00059.\n",
            "Epoch 4/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1859 - dir_acc: 0.5404\n",
            "Epoch 4: dir_acc improved from 0.53877 to 0.54045, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 4: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.1859 - dir_acc: 0.5404 - val_loss: 0.1557 - val_dir_acc: 0.5782 - lr: 5.9000e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0007533333333333334.\n",
            "Epoch 5/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1845 - dir_acc: 0.5459\n",
            "Epoch 5: dir_acc improved from 0.54045 to 0.54594, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 5: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.1845 - dir_acc: 0.5459 - val_loss: 0.2296 - val_dir_acc: 0.5306 - lr: 7.5333e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0009166666666666668.\n",
            "Epoch 6/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1727 - dir_acc: 0.5463\n",
            "Epoch 6: dir_acc improved from 0.54594 to 0.54631, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 6: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 97ms/step - loss: 0.1727 - dir_acc: 0.5463 - val_loss: 0.1610 - val_dir_acc: 0.5566 - lr: 9.1667e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.00108.\n",
            "Epoch 7/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1703 - dir_acc: 0.5603\n",
            "Epoch 7: dir_acc improved from 0.54631 to 0.56025, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 7: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 97ms/step - loss: 0.1703 - dir_acc: 0.5603 - val_loss: 0.1978 - val_dir_acc: 0.4999 - lr: 0.0011\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.0012433333333333335.\n",
            "Epoch 8/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1640 - dir_acc: 0.5668\n",
            "Epoch 8: dir_acc improved from 0.56025 to 0.56685, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 8: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.1640 - dir_acc: 0.5668 - val_loss: 0.1748 - val_dir_acc: 0.5423 - lr: 0.0012\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 0.0014066666666666667.\n",
            "Epoch 9/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1557 - dir_acc: 0.5750\n",
            "Epoch 9: dir_acc improved from 0.56685 to 0.57503, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 9: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.1557 - dir_acc: 0.5750 - val_loss: 0.1790 - val_dir_acc: 0.5559 - lr: 0.0014\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 0.00157.\n",
            "Epoch 10/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1643 - dir_acc: 0.5728\n",
            "Epoch 10: dir_acc did not improve from 0.57503\n",
            "\n",
            "Epoch 10: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 92ms/step - loss: 0.1643 - dir_acc: 0.5728 - val_loss: 0.2054 - val_dir_acc: 0.5619 - lr: 0.0016\n",
            "\n",
            "Epoch 11: LearningRateScheduler setting learning rate to 0.0017333333333333335.\n",
            "Epoch 11/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1595 - dir_acc: 0.5790\n",
            "Epoch 11: dir_acc improved from 0.57503 to 0.57898, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 11: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.1595 - dir_acc: 0.5790 - val_loss: 0.2498 - val_dir_acc: 0.5215 - lr: 0.0017\n",
            "\n",
            "Epoch 12: LearningRateScheduler setting learning rate to 0.0018966666666666667.\n",
            "Epoch 12/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1519 - dir_acc: 0.5843\n",
            "Epoch 12: dir_acc improved from 0.57898 to 0.58430, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 12: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.1519 - dir_acc: 0.5843 - val_loss: 0.1984 - val_dir_acc: 0.5208 - lr: 0.0019\n",
            "\n",
            "Epoch 13: LearningRateScheduler setting learning rate to 0.0020599999999999998.\n",
            "Epoch 13/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1588 - dir_acc: 0.5736\n",
            "Epoch 13: dir_acc did not improve from 0.58430\n",
            "\n",
            "Epoch 13: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 93ms/step - loss: 0.1588 - dir_acc: 0.5736 - val_loss: 0.2069 - val_dir_acc: 0.5430 - lr: 0.0021\n",
            "\n",
            "Epoch 14: LearningRateScheduler setting learning rate to 0.0022233333333333332.\n",
            "Epoch 14/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1507 - dir_acc: 0.5964\n",
            "Epoch 14: dir_acc improved from 0.58430 to 0.59635, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 14: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.1507 - dir_acc: 0.5964 - val_loss: 0.1726 - val_dir_acc: 0.5109 - lr: 0.0022\n",
            "\n",
            "Epoch 15: LearningRateScheduler setting learning rate to 0.0023866666666666667.\n",
            "Epoch 15/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1438 - dir_acc: 0.5988\n",
            "Epoch 15: dir_acc improved from 0.59635 to 0.59878, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 15: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 96ms/step - loss: 0.1438 - dir_acc: 0.5988 - val_loss: 0.1891 - val_dir_acc: 0.5152 - lr: 0.0024\n",
            "\n",
            "Epoch 16: LearningRateScheduler setting learning rate to 0.0025499999999999997.\n",
            "Epoch 16/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1467 - dir_acc: 0.5943\n",
            "Epoch 16: dir_acc did not improve from 0.59878\n",
            "\n",
            "Epoch 16: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 94ms/step - loss: 0.1467 - dir_acc: 0.5943 - val_loss: 0.1646 - val_dir_acc: 0.5207 - lr: 0.0026\n",
            "\n",
            "Epoch 17: LearningRateScheduler setting learning rate to 0.0027133333333333332.\n",
            "Epoch 17/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1429 - dir_acc: 0.5983\n",
            "Epoch 17: dir_acc did not improve from 0.59878\n",
            "\n",
            "Epoch 17: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 17s 93ms/step - loss: 0.1429 - dir_acc: 0.5983 - val_loss: 0.2238 - val_dir_acc: 0.5275 - lr: 0.0027\n",
            "\n",
            "Epoch 18: LearningRateScheduler setting learning rate to 0.0028766666666666667.\n",
            "Epoch 18/100\n",
            "188/188 [==============================] - ETA: 0s - loss: 0.1431 - dir_acc: 0.6057\n",
            "Epoch 18: dir_acc improved from 0.59878 to 0.60568, saving model to transformer_train_model.keras\n",
            "\n",
            "Epoch 18: val_dir_acc did not improve from 0.58628\n",
            "188/188 [==============================] - 18s 95ms/step - loss: 0.1431 - dir_acc: 0.6057 - val_loss: 0.1756 - val_dir_acc: 0.5403 - lr: 0.0029\n",
            "\n",
            "Epoch 19: LearningRateScheduler setting learning rate to 0.0030399999999999997.\n",
            "Epoch 19/100\n",
            "153/188 [=======================>......] - ETA: 3s - loss: 0.1449 - dir_acc: 0.6040"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 100\n",
        "model.fit(train_sequences, train_labels,\n",
        "          validation_data=(validation_sequences, validation_labels),\n",
        "          epochs=EPOCHS,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          shuffle=True,\n",
        "          callbacks=[checkpoint_callback_train, checkpoint_callback_val, get_lr_callback(batch_size=BATCH_SIZE, epochs=EPOCHS)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFpSqzgXCE4K"
      },
      "outputs": [],
      "source": [
        "# Load Weights\n",
        "model.load_weights(\"transformer_val_model.keras\")\n",
        "\n",
        "# Make predictions\n",
        "accuracy = model.evaluate(test_sequences, test_labels)[1]\n",
        "print(f\"{accuracy=}\")\n",
        "\n",
        "# Calculate additional metrics as needed\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "predictions = model.predict(test_sequences)\n",
        "r2 = r2_score(test_labels[:, 1], predictions[:, 0])\n",
        "print(f\"R-squared: {r2}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}